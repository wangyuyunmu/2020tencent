{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 835 kB/s eta 0:00:01     |██████████████████████████      | 307 kB 835 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras) (1.4.1)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import SGD,Adam,RMSprop\n",
    "# from keras.layers import Dense, Input, LSTM, Embedding,Dropout,Bidirectional,Flatten\n",
    "from keras.layers import *\n",
    "import os\n",
    "\n",
    "# from __future__ import print_function\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position_Embedding\n",
    "#! -*- coding: utf-8 -*-\n",
    "#%%\n",
    "\n",
    "class Position_Embedding(Layer):\n",
    " \n",
    "    def __init__(self, size=None, mode='sum', **kwargs):\n",
    "        self.size = size #必须为偶数\n",
    "        self.mode = mode\n",
    "        super(Position_Embedding, self).__init__(**kwargs)\n",
    " \n",
    "    def call(self, x):\n",
    "        if (self.size == None) or (self.mode == 'sum'):\n",
    "            self.size = int(x.shape[-1])\n",
    "        batch_size,seq_len = K.shape(x)[0],K.shape(x)[1]\n",
    "        position_j = 1. / K.pow(10000., \\\n",
    "                                 2 * K.arange(self.size / 2, dtype='float32' \\\n",
    "                               ) / self.size)\n",
    "        position_j = K.expand_dims(position_j, 0)\n",
    "        position_i = K.cumsum(K.ones_like(x[:,:,0]), 1)-1 #K.arange不支持变长，只好用这种方法生成\n",
    "        position_i = K.expand_dims(position_i, 2)\n",
    "        position_ij = K.dot(position_i, position_j)\n",
    "        position_ij = K.concatenate([K.cos(position_ij), K.sin(position_ij)], 2)\n",
    "        if self.mode == 'sum':\n",
    "            return position_ij + x\n",
    "        elif self.mode == 'concat':\n",
    "            return K.concatenate([position_ij, x], 2)\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.mode == 'sum':\n",
    "            return input_shape\n",
    "        elif self.mode == 'concat':\n",
    "            return (input_shape[0], input_shape[1], input_shape[2]+self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "\n",
    "class Attention(Layer):\n",
    " \n",
    "    def __init__(self, nb_head=8, size_per_head=4, **kwargs):\n",
    "        self.nb_head = nb_head\n",
    "        self.size_per_head = size_per_head\n",
    "        self.output_dim = nb_head*size_per_head\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        self.WQ = self.add_weight(name='WQ',\n",
    "                                  shape=(input_shape[0][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WK = self.add_weight(name='WK',\n",
    "                                  shape=(input_shape[1][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WV = self.add_weight(name='WV',\n",
    "                                  shape=(input_shape[2][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    " \n",
    "    def Mask(self, inputs, seq_len, mode='mul'):\n",
    "        if seq_len == None:\n",
    "            return inputs\n",
    "        else:\n",
    "            mask = K.one_hot(seq_len[:,0], K.shape(inputs)[1])\n",
    "            mask = 1 - K.cumsum(mask, 1)\n",
    "            for _ in range(len(inputs.shape)-2):\n",
    "                mask = K.expand_dims(mask, 2)\n",
    "            if mode == 'mul':\n",
    "                return inputs * mask\n",
    "            if mode == 'add':\n",
    "                return inputs - (1 - mask) * 1e12\n",
    " \n",
    "    def call(self, x):\n",
    "        #如果只传入Q_seq,K_seq,V_seq，那么就不做Mask\n",
    "        #如果同时传入Q_seq,K_seq,V_seq,Q_len,V_len，那么对多余部分做Mask\n",
    "        if len(x) == 3:\n",
    "            Q_seq,K_seq,V_seq = x\n",
    "            Q_len,V_len = None,None\n",
    "        elif len(x) == 5:\n",
    "            Q_seq,K_seq,V_seq,Q_len,V_len = x\n",
    "        #对Q、K、V做线性变换\n",
    "        Q_seq = K.dot(Q_seq, self.WQ)\n",
    "        Q_seq = K.reshape(Q_seq, (-1, K.shape(Q_seq)[1], self.nb_head, self.size_per_head))\n",
    "        Q_seq = K.permute_dimensions(Q_seq, (0,2,1,3))\n",
    "        K_seq = K.dot(K_seq, self.WK)\n",
    "        K_seq = K.reshape(K_seq, (-1, K.shape(K_seq)[1], self.nb_head, self.size_per_head))\n",
    "        K_seq = K.permute_dimensions(K_seq, (0,2,1,3))\n",
    "        V_seq = K.dot(V_seq, self.WV)\n",
    "        V_seq = K.reshape(V_seq, (-1, K.shape(V_seq)[1], self.nb_head, self.size_per_head))\n",
    "        V_seq = K.permute_dimensions(V_seq, (0,2,1,3))\n",
    "        #计算内积，然后mask，然后softmax\n",
    "        A = K.batch_dot(Q_seq, K_seq, axes=[3,3]) / self.size_per_head**0.5\n",
    "        A = K.permute_dimensions(A, (0,3,2,1))\n",
    "        A = self.Mask(A, V_len, 'add')\n",
    "        A = K.permute_dimensions(A, (0,3,2,1))\n",
    "        A = K.softmax(A)\n",
    "        #输出并mask\n",
    "        O_seq = K.batch_dot(A, V_seq, axes=[3,2])\n",
    "        O_seq = K.permute_dimensions(O_seq, (0,2,1,3))\n",
    "        O_seq = K.reshape(O_seq, (-1, K.shape(O_seq)[1], self.output_dim))\n",
    "        O_seq = self.Mask(O_seq, Q_len, 'mul')\n",
    "        return O_seq\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    print('loading data ... \\n')\n",
    "    with h5py.File('../../../get_w2v_feat/w2v1_pre_ad/word_test_ad_w2v_w200.h5', 'r') as f:\n",
    "        data = np.array(f.get('word_data'))\n",
    "    print('get data ... \\n')\n",
    "    return data\n",
    "\n",
    "def load_data2():\n",
    "    with h5py.File('../../../get_w2v_feat/w2v1_pre_advertiser/word_test_advertiser_w2v_w200.h5', 'r') as f:\n",
    "        data = np.array(f.get('word_data'))\n",
    "    return data\n",
    "def load_data3():\n",
    "    with h5py.File('../../../get_w2v_feat/w2v1_pre_creative_id/word_test_creative_w2v_w200.h5', 'r') as f:\n",
    "        data = np.array(f.get('word_data'))\n",
    "    return data\n",
    "\n",
    "def load_data4():\n",
    "    with h5py.File('../../../get_w2v_feat/w2v1_pre_industry/word_test_industry_w2v_w200.h5', 'r') as f:\n",
    "        data = np.array(f.get('word_data'))\n",
    "    return data\n",
    "def load_data5():\n",
    "    with h5py.File('../../../get_w2v_feat/w2v1_pre_product_id/word_test_product_id_w2v_w200.h5', 'r') as f:\n",
    "        data = np.array(f.get('word_data'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "from keras.utils import CustomObjectScope\n",
    "with CustomObjectScope({'Attention': Attention}):\n",
    "    lstm_model_path_age1 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_age_adm_w200_1.310-0.463-001-1.377-0.438.hdf5'\n",
    "    model_age1 = keras.models.load_model(lstm_model_path_age1)\n",
    "    lstm_model_path_age2 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_age_adm_w200_1.316-0.463-001-1.378-0.437.hdf5'\n",
    "    model_age2 = keras.models.load_model(lstm_model_path_age2)\n",
    "    lstm_model_path_age3 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_age_adm_w200_1.324-0.458-001-1.377-0.438.hdf5'\n",
    "    model_age3 = keras.models.load_model(lstm_model_path_age3)\n",
    "    lstm_model_path_age4 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_age_adm_w200_1.326-0.456-001-1.379-0.437.hdf5'\n",
    "    model_age4 = keras.models.load_model(lstm_model_path_age4)\n",
    "    lstm_model_path_age5 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_age_adm_w200_1.331-0.456-001-1.378-0.438.hdf5'\n",
    "    model_age5 = keras.models.load_model(lstm_model_path_age5)\n",
    "\n",
    "#     lstm_model_path_gender1 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_gender_adm_w200_0.169-0.941-001-0.181-0.936.hdf5'\n",
    "#     model_gender1 = keras.models.load_model(lstm_model_path_gender1)\n",
    "#     lstm_model_path_gender2 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_gender_adm_w200_0.171-0.939-001-0.180-0.936.hdf5'\n",
    "#     model_gender2 = keras.models.load_model(lstm_model_path_gender2)\n",
    "#     lstm_model_path_gender3 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_gender_adm_w200_0.171-0.941-001-0.181-0.935.hdf5'\n",
    "#     model_gender3 = keras.models.load_model(lstm_model_path_gender3)\n",
    "#     lstm_model_path_gender4 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_gender_adm_w200_0.176-0.938-001-0.180-0.936.hdf5'\n",
    "#     model_gender4 = keras.models.load_model(lstm_model_path_gender4)\n",
    "#     lstm_model_path_gender5 = '../../../w2v_model5_lstm/attention_comb/cross_multi_attention_aver_gender_adm_w200_0.174-0.939-001-0.181-0.935.hdf5'\n",
    "#     model_gender5 = keras.models.load_model(lstm_model_path_gender5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data...\n",
      "loading data ... \n",
      "\n",
      "get data ... \n",
      "\n",
      "pre age ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'probs_age' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5d59e2428397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mpre_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mpre_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_age\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probs_age' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print('load data...')\n",
    "data_ad = data_load()\n",
    "data_advertiser = load_data2()\n",
    "data_creative = load_data3()\n",
    "data_industry = load_data4()\n",
    "data_product_id = load_data5()\n",
    "\n",
    "\n",
    "data_age = [data_ad,data_advertiser,data_creative]\n",
    "data_gender = [data_ad,data_advertiser,data_creative,data_industry,data_product_id]\n",
    "\n",
    "# print('pre gender ...')\n",
    "\n",
    "# probs_gender1 = model_gender1.predict(data_gender, verbose=0)\n",
    "# probs_gender2 = model_gender2.predict(data_gender, verbose=0)\n",
    "# probs_gender3 = model_gender3.predict(data_gender, verbose=0)\n",
    "# probs_gender4 = model_gender4.predict(data_gender, verbose=0)\n",
    "# probs_gender5 = model_gender5.predict(data_gender, verbose=0)\n",
    "\n",
    "# pre_gender = (probs_gender1 + probs_gender2+probs_gender3+probs_gender4+probs_gender5)/5\n",
    "\n",
    "# pre_gender = np.array(probs_gender>0.5).astype('int')\n",
    "# pre_gender = pre_gender + 1\n",
    "\n",
    "\n",
    "print('pre age ...')\n",
    "\n",
    "probs_age1 = model_age1.predict(data_age, verbose=0)\n",
    "probs_age2 = model_age2.predict(data_age, verbose=0)\n",
    "probs_age3 = model_age3.predict(data_age, verbose=0)\n",
    "probs_age4 = model_age4.predict(data_age, verbose=0)\n",
    "probs_age5 = model_age5.predict(data_age, verbose=0)\n",
    "\n",
    "pre_age = (probs_age1+probs_age2+probs_age3+probs_age4+probs_age5)/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_age = (probs_age1+probs_age2+probs_age3+probs_age4+probs_age5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pre_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(pre_age)\n",
    "res.to_csv('submission_age_pro.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_age = np.reshape(np.argmax(pre_age, axis=1),[-1])\n",
    "pre_age = pre_age + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id = np.array(range(3000001,4000001))\n",
    "res = pd.DataFrame(test_user_id)\n",
    "res.columns = [['user_id']]\n",
    "\n",
    "res['predicted_age']=pre_age\n",
    "# res['predicted_gender']=pre_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000001</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000002</td>\n",
       "      <td>0.997314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000003</td>\n",
       "      <td>0.790318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000004</td>\n",
       "      <td>0.194321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000005</td>\n",
       "      <td>0.007194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3999996</td>\n",
       "      <td>0.011047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>3999997</td>\n",
       "      <td>0.045251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>3999998</td>\n",
       "      <td>0.010197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>3999999</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4000000</td>\n",
       "      <td>0.003076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  predicted_gender\n",
       "0       3000001          0.005375\n",
       "1       3000002          0.997314\n",
       "2       3000003          0.790318\n",
       "3       3000004          0.194321\n",
       "4       3000005          0.007194\n",
       "...         ...               ...\n",
       "999995  3999996          0.011047\n",
       "999996  3999997          0.045251\n",
       "999997  3999998          0.010197\n",
       "999998  3999999          0.008800\n",
       "999999  4000000          0.003076\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_gender = gender['predicted_gender'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00537505, 0.9973135 , 0.79031765, ..., 0.01019735, 0.00879961,\n",
       "       0.00307634])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_gender = np.array(pre_gender>0.5).astype('int')\n",
    "pre_gender = pre_gender + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['predicted_gender']=pre_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
