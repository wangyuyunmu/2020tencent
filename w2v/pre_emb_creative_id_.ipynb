{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras==2.2.4\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 672 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (5.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.16.4)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from h5py) (1.16.4)\n",
      "Requirement already satisfied: six in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from h5py) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting gensim\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 3.8 MB/s eta 0:00:01       | 9.4 MB 1.1 MB/s eta 0:00:14\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from gensim) (1.14.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/74/77/744c79da6e66691e3500b6dffff29bdd787015eae817d594791edc7b719b/smart_open-2.0.0.tar.gz (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 64.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from gensim) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.20.1)\n",
      "Collecting boto\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 1.6 MB/s eta 0:00:01     |██████████████████████▏         | 942 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/d5/08/da07182e39a1b47abeb791fcff71c04016264dd462a19e20c02d7ff69ef3/boto3-1.13.26-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 75.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Collecting idna<2.8,>=2.5\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 51.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.25,>=1.21.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 57.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.17.0,>=1.16.26\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/d4/b0/9ff467a3318aca0dcf83feafe6e5ef737f17d1ed5348412913ae0b35907a/botocore-1.16.26-py2.py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 3.1 MB/s eta 0:00:01              | 1.8 MB 3.1 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 51.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "\u001b[K     |████████████████████████████████| 547 kB 68.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from botocore<1.17.0,>=1.16.26->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101341 sha256=af2306fc552099ac7b4cb479aa0b7e1b19492d43921ff5af36f3bb89937a0347\n",
      "  Stored in directory: /home/tione/.cache/pip/wheels/54/7f/ad/18624c030ede84ebb5f4bcd3a6cdfab71662eccc4f4042df14\n",
      "Successfully built smart-open\n",
      "Installing collected packages: boto, jmespath, docutils, urllib3, botocore, s3transfer, boto3, smart-open, gensim, idna\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.7\n",
      "    Uninstalling urllib3-1.25.7:\n",
      "      Successfully uninstalled urllib3-1.25.7\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.8\n",
      "    Uninstalling idna-2.8:\n",
      "      Successfully uninstalled idna-2.8\n",
      "Successfully installed boto-2.49.0 boto3-1.13.26 botocore-1.16.26 docutils-0.15.2 gensim-3.8.3 idna-2.7 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.0.0 urllib3-1.24.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading trian data ... \n",
      "\n",
      "\n",
      "loading trian data  over  ... \n",
      "\n",
      "\n",
      "loading test data ... \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/900000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data  over  ... \n",
      "\n",
      "\n",
      "get list data ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900000/900000 [07:40<00:00, 1952.97it/s]\n",
      "100%|██████████| 1000000/1000000 [08:35<00:00, 1938.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "\n",
    "print('loading trian data ... \\n\\n')\n",
    "train_click = pd.read_csv('../../train_preliminary/click_log.csv').sort_values(by = ['user_id','time'])\n",
    "train_ad = pd.read_csv('../../train_preliminary/ad.csv')\n",
    "train_click = train_click.merge(train_ad,on = 'creative_id',how = 'left')\n",
    "train_click = train_click[['user_id','time','creative_id']].sort_values(by = ['user_id','time'])\n",
    "train_click = train_click.set_index('user_id')\n",
    "print('loading trian data  over  ... \\n\\n')\n",
    "\n",
    "\n",
    "print('loading test data ... \\n\\n')\n",
    "test_click = pd.read_csv('../../test/click_log.csv').sort_values(by = ['user_id','time'])\n",
    "test_ad = pd.read_csv('../../test/ad.csv')\n",
    "test_click = test_click.merge(test_ad,on = 'creative_id',how = 'left')\n",
    "test_click = test_click[['user_id','time','creative_id']].sort_values(by = ['user_id','time'])\n",
    "test_click = test_click.set_index('user_id')\n",
    "print('loading test data  over  ... \\n\\n')\n",
    "\n",
    "\n",
    "def get_str_data():\n",
    "    text_data = []\n",
    "    for i in tqdm.tqdm(range(1, 900001)):\n",
    "#     for i in tqdm.tqdm(range(1, 9001)):\n",
    "        train_user_ad = train_click.loc[i, 'creative_id'].values\n",
    "        text = [str(x) for x in train_user_ad]\n",
    "        text_data.append(text)\n",
    "    for i in tqdm.tqdm(range(3000001, 4000001)):\n",
    "#     for i in tqdm.tqdm(range(3000001, 3001001)):\n",
    "        test_user_ad = test_click.loc[i, 'creative_id'].values\n",
    "        text = [str(x) for x in test_user_ad]\n",
    "        text_data.append(text)\n",
    "    return text_data\n",
    "\n",
    "print('get list data ...\\n\\n')\n",
    "data = get_str_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# del train_click\n",
    "# del test_click\n",
    "# del train_ad\n",
    "# del test_ad\n",
    "\n",
    "model = Word2Vec(data, size=32, window=100, min_count=0, workers=8, sg=1, iter = 10 )\n",
    "\n",
    "print('saving model ... \\n\\n')\n",
    "model.save('word2vec_creative_id_pre_embed_size_32_w100_count_0')\n",
    "print('model saved ... \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = Word2Vec.load(\"word2vec_ad_id_pre_embed_size_32_w50_count_0\")\n",
    "#1,导入w2v模型\n",
    "# w2v_model = Word2Vec.load(\"../../get_w2v_feat/word2vec.model\")\n",
    "## 2 构造包含所有词语的 list，以及初始化 “词语-序号”字典 和 “词向量”矩阵\n",
    "vocab_list = [word for word, Vocab in model.wv.vocab.items()]# 存储 所有的 词语\n",
    "word_index = {\" \": 0}# 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n",
    "word_vector = {} # 初始化`[word : vector]`字典\n",
    "# 初始化存储所有向量的大矩阵，留意其中多一位（首行），词向量全为 0，用于 padding补零。\n",
    "# 行数 为 所有单词数+1 比如 10000+1 ； 列数为 词向量“维度”比如100。\n",
    "embeddings_matrix = np.zeros((len(vocab_list) + 1, model.vector_size))\n",
    "## 3 填充 上述 的字典 和 大矩阵\n",
    "for i in tqdm.tqdm(range(len(vocab_list))):\n",
    "    # print(i)\n",
    "    word = vocab_list[i]  # 每个词语\n",
    "    word_index[word] = i + 1 # 词语：序号\n",
    "    word_vector[word] = model.wv[word] # 词语：词向量\n",
    "    embeddings_matrix[i + 1] = model.wv[word]  # 词向量矩阵\n",
    "\n",
    "import h5py\n",
    "with h5py.File('embeddings_matrix_creative_size_32_w100_count_0.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"embeddings_matrix\",  data=embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 序号化 文本，tokenizer句子，并返回每个句子所对应的词语索引\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "texts = data\n",
    "data_pad = []\n",
    "for sentence in tqdm.tqdm(texts):\n",
    "    new_txt = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            new_txt.append(word_index[word])  # 把句子中的 词语转化为index\n",
    "        except:\n",
    "            new_txt.append(0)\n",
    "\n",
    "    data_pad.append(new_txt)\n",
    "    \n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "texts_pad = sequence.pad_sequences(data_pad, maxlen = MAX_SEQUENCE_LENGTH)  # 使用kears的内置函数padding对齐句子,好处是输出numpy数组，不用自己转化了\n",
    "\n",
    "\n",
    "train_data = texts_pad[:900000,:]\n",
    "test_data = texts_pad[900000:,:]\n",
    "with h5py.File('word_train_creative_w2v_w100.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"word_data\",  data=train_data)\n",
    "with h5py.File('word_test_creative_w2v_w100.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"word_data\",  data=test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
