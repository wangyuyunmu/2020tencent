{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras==2.2.4\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 672 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (5.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.16.4)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from h5py) (1.16.4)\n",
      "Requirement already satisfied: six in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from h5py) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: gensim in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from gensim) (1.16.4)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.20.1)\n",
      "Requirement already satisfied: boto in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.14.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.7)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.3 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.3->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.3->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading trian data ... \n",
      "\n",
      "\n",
      "loading trian data  over  ... \n",
      "\n",
      "\n",
      "loading test data ... \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/900000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data  over  ... \n",
      "\n",
      "\n",
      "get list data ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900000/900000 [07:43<00:00, 1943.46it/s]\n",
      "100%|██████████| 1000000/1000000 [08:35<00:00, 1939.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "\n",
    "print('loading trian data ... \\n\\n')\n",
    "train_click = pd.read_csv('../../train_preliminary/click_log.csv').sort_values(by = ['user_id','time'])\n",
    "train_ad = pd.read_csv('../../train_preliminary/ad.csv')\n",
    "train_click = train_click.merge(train_ad,on = 'creative_id',how = 'left')\n",
    "train_click = train_click[['user_id','time','ad_id']].sort_values(by = ['user_id','time'])\n",
    "train_click = train_click.set_index('user_id')\n",
    "print('loading trian data  over  ... \\n\\n')\n",
    "\n",
    "\n",
    "print('loading test data ... \\n\\n')\n",
    "test_click = pd.read_csv('../../test/click_log.csv').sort_values(by = ['user_id','time'])\n",
    "test_ad = pd.read_csv('../../test/ad.csv')\n",
    "test_click = test_click.merge(test_ad,on = 'creative_id',how = 'left')\n",
    "test_click = test_click[['user_id','time','ad_id']].sort_values(by = ['user_id','time'])\n",
    "test_click = test_click.set_index('user_id')\n",
    "print('loading test data  over  ... \\n\\n')\n",
    "\n",
    "\n",
    "def get_str_data():\n",
    "    text_data = []\n",
    "    for i in tqdm.tqdm(range(1, 900001)):\n",
    "#     for i in tqdm.tqdm(range(1, 9001)):\n",
    "        train_user_ad = train_click.loc[i, 'ad_id'].values\n",
    "        text = [str(x) for x in train_user_ad]\n",
    "        text_data.append(text)\n",
    "    for i in tqdm.tqdm(range(3000001, 4000001)):\n",
    "#     for i in tqdm.tqdm(range(3000001, 3001001)):\n",
    "        test_user_ad = test_click.loc[i, 'ad_id'].values\n",
    "        text = [str(x) for x in test_user_ad]\n",
    "        text_data.append(text)\n",
    "    return text_data\n",
    "\n",
    "print('get list data ...\\n\\n')\n",
    "data = get_str_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model ... \n",
      "\n",
      "\n",
      "model saved ... \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# del train_click\n",
    "# del test_click\n",
    "# del train_ad\n",
    "# del test_ad\n",
    "\n",
    "\n",
    "model = Word2Vec(data, size=32, window=200, min_count=5, workers=8, sg=1)\n",
    "\n",
    "print('saving model ... \\n\\n')\n",
    "model.save('word2vec_ad_id_pre_embed_size_32_w200_count_0')\n",
    "print('model saved ... \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1009977/1009977 [00:07<00:00, 140533.72it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = Word2Vec.load(\"word2vec_ad_id_pre_embed_size_32_w50_count_0\")\n",
    "#1,导入w2v模型\n",
    "# w2v_model = Word2Vec.load(\"../../get_w2v_feat/word2vec.model\")\n",
    "## 2 构造包含所有词语的 list，以及初始化 “词语-序号”字典 和 “词向量”矩阵\n",
    "vocab_list = [word for word, Vocab in model.wv.vocab.items()]# 存储 所有的 词语\n",
    "word_index = {\" \": 0}# 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n",
    "word_vector = {} # 初始化`[word : vector]`字典\n",
    "# 初始化存储所有向量的大矩阵，留意其中多一位（首行），词向量全为 0，用于 padding补零。\n",
    "# 行数 为 所有单词数+1 比如 10000+1 ； 列数为 词向量“维度”比如100。\n",
    "embeddings_matrix = np.zeros((len(vocab_list) + 1, model.vector_size))\n",
    "## 3 填充 上述 的字典 和 大矩阵\n",
    "for i in tqdm.tqdm(range(len(vocab_list))):\n",
    "    # print(i)\n",
    "    word = vocab_list[i]  # 每个词语\n",
    "    word_index[word] = i + 1 # 词语：序号\n",
    "    word_vector[word] = model.wv[word] # 词语：词向量\n",
    "    embeddings_matrix[i + 1] = model.wv[word]  # 词向量矩阵\n",
    "\n",
    "import h5py\n",
    "with h5py.File('embeddings_matrix_ad_size_32_w200_count_0.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"embeddings_matrix\",  data=embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "100%|██████████| 1900000/1900000 [00:48<00:00, 38824.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# 序号化 文本，tokenizer句子，并返回每个句子所对应的词语索引\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "texts = data\n",
    "data_pad = []\n",
    "for sentence in tqdm.tqdm(texts):\n",
    "    new_txt = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            new_txt.append(word_index[word])  # 把句子中的 词语转化为index\n",
    "        except:\n",
    "            new_txt.append(0)\n",
    "\n",
    "    data_pad.append(new_txt)\n",
    "    \n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "texts_pad = sequence.pad_sequences(data_pad, maxlen = MAX_SEQUENCE_LENGTH)  # 使用kears的内置函数padding对齐句子,好处是输出numpy数组，不用自己转化了\n",
    "\n",
    "\n",
    "train_data = texts_pad[:900000,:]\n",
    "test_data = texts_pad[900000:,:]\n",
    "with h5py.File('word_train_ad_w2v_w200.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"word_data\",  data=train_data)\n",
    "with h5py.File('word_test_ad_w2v_w200.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"word_data\",  data=test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
