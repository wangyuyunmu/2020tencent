{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting lightgbm\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 800 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/envs/python3/lib/python3.6/site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python3/lib/python3.6/site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python3/lib/python3.6/site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python3/lib/python3.6/site-packages (from scikit-learn->lightgbm) (0.14.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/python3/lib/python3.6/site-packages (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "np.random.seed(2020)\n",
    "\n",
    "\n",
    "def lgb_model_age(train_x, test_x,train_y, test_y):\n",
    "    model = lgb.LGBMClassifier (objective = 'multiclass',\n",
    "                                learning_rate=0.06787,\n",
    "                                num_leaves =57,\n",
    "                                colsample_bytree = 0.9712,\n",
    "                                reg_alpha= 0.06883,\n",
    "                                reg_lambda= 0.09217,\n",
    "                                subsample =  0.9,\n",
    "                                n_estimators = 10000)\n",
    "    model.fit(train_x,train_y,early_stopping_rounds=100,eval_set=[(train_x,train_y),(test_x,test_y)],verbose = 10)\n",
    "    \n",
    "    \n",
    "    # 模型存储\n",
    "    joblib.dump(model, 'w2v_lgb_age_2_0.2.pkl')\n",
    "    # 模型加载\n",
    "    # model = joblib.load('lgb_cough.pkl')\n",
    "    # # 模型预测\n",
    "    # y_t_pred = model.predict(test_x, num_iteration=model.best_iteration_)\n",
    "    \n",
    "    y_t_pred = model.predict(test_x)\n",
    "\n",
    "    # print(model.get_score(importance_type='weight'))\n",
    "    cm = confusion_matrix(test_y, y_t_pred)\n",
    "    np.set_printoptions(precision=3)                                    # 显示精度\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # 将样本矩阵转化为比率\n",
    "\n",
    "\n",
    "    print('age************************************')\n",
    "    print('confusion_matrix is \\n {:} \\n '.format(cm_normalized))\n",
    "    print('test acc is \\n {:} \\n '.format(np.sum(test_y==y_t_pred)/len(test_y)))\n",
    "    print(classification_report(test_y,y_t_pred))\n",
    "    print('accuracy is %f , sen is %f,spe is %f ' % (accuracy_score(test_y, y_t_pred) * 100,\n",
    "                                                     cm_normalized[0][0],cm_normalized[1][1] ))\n",
    "\n",
    "    return accuracy_score(test_y, y_t_pred)\n",
    "\n",
    "def lgb_model_gender(train_x, test_x,train_y, test_y):\n",
    "    model = lgb.LGBMClassifier (objective = 'binary',\n",
    "                               learning_rate=0.0376,\n",
    "                                num_leaves = 22,\n",
    "                                colsample_bytree = 0.23,\n",
    "                                reg_alpha= 0.096,\n",
    "                                reg_lambda= 0.0899,\n",
    "                                subsample =  0.99,\n",
    "                                n_estimators = 10000)\n",
    "    model.fit(train_x,train_y,early_stopping_rounds=100,eval_set=[(train_x,train_y),(test_x,test_y)],verbose = 10)\n",
    "    \n",
    "    # 模型存储\n",
    "    joblib.dump(model, 'w2v_lgb_gender_2_0.2.pkl')\n",
    "    \n",
    "    y_t_pred = model.predict(test_x)\n",
    "\n",
    "    # print(model.get_score(importance_type='weight'))\n",
    "    cm = confusion_matrix(test_y, y_t_pred)\n",
    "    np.set_printoptions(precision=3)                                    # 显示精度\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # 将样本矩阵转化为比率\n",
    "\n",
    "    print('gender************************************')\n",
    "    print('confusion_matrix is \\n {:} \\n '.format(cm_normalized))\n",
    "    print('test acc is \\n {:} \\n '.format(np.sum(test_y==y_t_pred)/len(test_y)))\n",
    "    print(classification_report(test_y,y_t_pred))\n",
    "    print('accuracy is %f , sen is %f,spe is %f ' % (accuracy_score(test_y, y_t_pred) * 100,\n",
    "                                                     cm_normalized[0][0],cm_normalized[1][1] ))\n",
    "    return accuracy_score(test_y, y_t_pred)\n",
    "def lgb_model_gender2(train_x, test_x,train_y, test_y):\n",
    "#     model = lgb.LGBMRegressor(n_estimators = 10000)\n",
    "#     model.fit(train_x,train_y,early_stopping_rounds=100,eval_set=[(train_x,train_y),(test_x,test_y)],verbose = 10)\n",
    "    \n",
    "    # 模型存储\n",
    "#     joblib.dump(model, 'w2v_gender_reg_2.pkl')\n",
    "    model = joblib.load('w2v_gender_reg_2.pkl')\n",
    "    \n",
    "    y_t_pred = model.predict(test_x)\n",
    "    \n",
    "    y_t_pred = [2 if i >1.5 else 1 for i in y_t_pred]\n",
    "\n",
    "    # print(model.get_score(importance_type='weight'))\n",
    "    cm = confusion_matrix(test_y, y_t_pred)\n",
    "    np.set_printoptions(precision=3)                                    # 显示精度\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # 将样本矩阵转化为比率\n",
    "\n",
    "    print('gender************************************')\n",
    "    print('confusion_matrix is \\n {:} \\n '.format(cm_normalized))\n",
    "    print('test acc is \\n {:} \\n '.format(np.sum(test_y==y_t_pred)/len(test_y)))\n",
    "    print(classification_report(test_y,y_t_pred))\n",
    "    print('accuracy is %f , sen is %f,spe is %f ' % (accuracy_score(test_y, y_t_pred) * 100,\n",
    "                                                     cm_normalized[0][0],cm_normalized[1][1] ))\n",
    "    return accuracy_score(test_y, y_t_pred)\n",
    "\n",
    "def load_data():\n",
    "    # user\n",
    "    data = pd.read_csv('../w2v_feat_data/train_data.csv')\n",
    "    label = data[['age','gender']]\n",
    "    \n",
    "    data = data.drop(['user_id','age','gender'],axis = 1)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分age的训练和测试数据\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.2,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's multi_logloss: 1.91644\tvalid_1's multi_logloss: 1.92408\n",
      "[20]\ttraining's multi_logloss: 1.84782\tvalid_1's multi_logloss: 1.86121\n",
      "[30]\ttraining's multi_logloss: 1.79936\tvalid_1's multi_logloss: 1.81791\n",
      "[40]\ttraining's multi_logloss: 1.76242\tvalid_1's multi_logloss: 1.786\n",
      "[50]\ttraining's multi_logloss: 1.73287\tvalid_1's multi_logloss: 1.7614\n",
      "[60]\ttraining's multi_logloss: 1.70835\tvalid_1's multi_logloss: 1.74169\n",
      "[70]\ttraining's multi_logloss: 1.68736\tvalid_1's multi_logloss: 1.72545\n",
      "[80]\ttraining's multi_logloss: 1.66909\tvalid_1's multi_logloss: 1.71179\n",
      "[90]\ttraining's multi_logloss: 1.65291\tvalid_1's multi_logloss: 1.70017\n",
      "[100]\ttraining's multi_logloss: 1.63821\tvalid_1's multi_logloss: 1.69006\n",
      "[110]\ttraining's multi_logloss: 1.6248\tvalid_1's multi_logloss: 1.6812\n",
      "[120]\ttraining's multi_logloss: 1.61241\tvalid_1's multi_logloss: 1.67339\n",
      "[130]\ttraining's multi_logloss: 1.60093\tvalid_1's multi_logloss: 1.66655\n",
      "[140]\ttraining's multi_logloss: 1.59017\tvalid_1's multi_logloss: 1.66025\n",
      "[150]\ttraining's multi_logloss: 1.57999\tvalid_1's multi_logloss: 1.65459\n",
      "[160]\ttraining's multi_logloss: 1.57032\tvalid_1's multi_logloss: 1.64948\n",
      "[170]\ttraining's multi_logloss: 1.56117\tvalid_1's multi_logloss: 1.6449\n",
      "[180]\ttraining's multi_logloss: 1.55241\tvalid_1's multi_logloss: 1.6406\n",
      "[190]\ttraining's multi_logloss: 1.54399\tvalid_1's multi_logloss: 1.63666\n",
      "[200]\ttraining's multi_logloss: 1.53586\tvalid_1's multi_logloss: 1.63306\n",
      "[210]\ttraining's multi_logloss: 1.52805\tvalid_1's multi_logloss: 1.62971\n",
      "[220]\ttraining's multi_logloss: 1.52047\tvalid_1's multi_logloss: 1.62655\n",
      "[230]\ttraining's multi_logloss: 1.51317\tvalid_1's multi_logloss: 1.62367\n",
      "[240]\ttraining's multi_logloss: 1.50605\tvalid_1's multi_logloss: 1.62099\n",
      "[250]\ttraining's multi_logloss: 1.49909\tvalid_1's multi_logloss: 1.61843\n",
      "[260]\ttraining's multi_logloss: 1.49233\tvalid_1's multi_logloss: 1.61607\n",
      "[270]\ttraining's multi_logloss: 1.48573\tvalid_1's multi_logloss: 1.61385\n",
      "[280]\ttraining's multi_logloss: 1.47923\tvalid_1's multi_logloss: 1.61173\n",
      "[290]\ttraining's multi_logloss: 1.47293\tvalid_1's multi_logloss: 1.60979\n",
      "[300]\ttraining's multi_logloss: 1.46677\tvalid_1's multi_logloss: 1.60794\n",
      "[310]\ttraining's multi_logloss: 1.46073\tvalid_1's multi_logloss: 1.60619\n",
      "[320]\ttraining's multi_logloss: 1.45479\tvalid_1's multi_logloss: 1.60447\n",
      "[330]\ttraining's multi_logloss: 1.44893\tvalid_1's multi_logloss: 1.60289\n",
      "[340]\ttraining's multi_logloss: 1.44314\tvalid_1's multi_logloss: 1.60139\n",
      "[350]\ttraining's multi_logloss: 1.43752\tvalid_1's multi_logloss: 1.59995\n",
      "[360]\ttraining's multi_logloss: 1.43197\tvalid_1's multi_logloss: 1.59856\n",
      "[370]\ttraining's multi_logloss: 1.42652\tvalid_1's multi_logloss: 1.59722\n",
      "[380]\ttraining's multi_logloss: 1.42113\tvalid_1's multi_logloss: 1.59599\n",
      "[390]\ttraining's multi_logloss: 1.41579\tvalid_1's multi_logloss: 1.59476\n",
      "[400]\ttraining's multi_logloss: 1.41057\tvalid_1's multi_logloss: 1.59363\n",
      "[410]\ttraining's multi_logloss: 1.40535\tvalid_1's multi_logloss: 1.59254\n",
      "[420]\ttraining's multi_logloss: 1.40025\tvalid_1's multi_logloss: 1.59155\n",
      "[430]\ttraining's multi_logloss: 1.3952\tvalid_1's multi_logloss: 1.59055\n",
      "[440]\ttraining's multi_logloss: 1.3902\tvalid_1's multi_logloss: 1.58953\n",
      "[450]\ttraining's multi_logloss: 1.38527\tvalid_1's multi_logloss: 1.5886\n",
      "[460]\ttraining's multi_logloss: 1.38042\tvalid_1's multi_logloss: 1.58775\n",
      "[470]\ttraining's multi_logloss: 1.37563\tvalid_1's multi_logloss: 1.58693\n",
      "[480]\ttraining's multi_logloss: 1.3709\tvalid_1's multi_logloss: 1.58614\n",
      "[490]\ttraining's multi_logloss: 1.36623\tvalid_1's multi_logloss: 1.58536\n",
      "[500]\ttraining's multi_logloss: 1.36159\tvalid_1's multi_logloss: 1.58465\n",
      "[510]\ttraining's multi_logloss: 1.35699\tvalid_1's multi_logloss: 1.58392\n",
      "[520]\ttraining's multi_logloss: 1.35247\tvalid_1's multi_logloss: 1.58317\n",
      "[530]\ttraining's multi_logloss: 1.34796\tvalid_1's multi_logloss: 1.58252\n",
      "[540]\ttraining's multi_logloss: 1.34352\tvalid_1's multi_logloss: 1.58186\n",
      "[550]\ttraining's multi_logloss: 1.33911\tvalid_1's multi_logloss: 1.58124\n",
      "[560]\ttraining's multi_logloss: 1.33475\tvalid_1's multi_logloss: 1.58063\n",
      "[570]\ttraining's multi_logloss: 1.33042\tvalid_1's multi_logloss: 1.58009\n",
      "[580]\ttraining's multi_logloss: 1.32615\tvalid_1's multi_logloss: 1.57959\n",
      "[590]\ttraining's multi_logloss: 1.32192\tvalid_1's multi_logloss: 1.57911\n",
      "[600]\ttraining's multi_logloss: 1.31776\tvalid_1's multi_logloss: 1.57859\n",
      "[610]\ttraining's multi_logloss: 1.31366\tvalid_1's multi_logloss: 1.57811\n",
      "[620]\ttraining's multi_logloss: 1.30955\tvalid_1's multi_logloss: 1.5777\n",
      "[630]\ttraining's multi_logloss: 1.30552\tvalid_1's multi_logloss: 1.57731\n",
      "[640]\ttraining's multi_logloss: 1.30149\tvalid_1's multi_logloss: 1.57685\n",
      "[650]\ttraining's multi_logloss: 1.29751\tvalid_1's multi_logloss: 1.57644\n",
      "[660]\ttraining's multi_logloss: 1.29358\tvalid_1's multi_logloss: 1.57612\n",
      "[670]\ttraining's multi_logloss: 1.28965\tvalid_1's multi_logloss: 1.57573\n",
      "[680]\ttraining's multi_logloss: 1.28579\tvalid_1's multi_logloss: 1.57537\n",
      "[690]\ttraining's multi_logloss: 1.28192\tvalid_1's multi_logloss: 1.57502\n",
      "[700]\ttraining's multi_logloss: 1.27816\tvalid_1's multi_logloss: 1.57474\n",
      "[710]\ttraining's multi_logloss: 1.27444\tvalid_1's multi_logloss: 1.57443\n",
      "[720]\ttraining's multi_logloss: 1.27068\tvalid_1's multi_logloss: 1.57416\n",
      "[730]\ttraining's multi_logloss: 1.26697\tvalid_1's multi_logloss: 1.57392\n",
      "[740]\ttraining's multi_logloss: 1.2633\tvalid_1's multi_logloss: 1.57363\n",
      "[750]\ttraining's multi_logloss: 1.25959\tvalid_1's multi_logloss: 1.5734\n",
      "[760]\ttraining's multi_logloss: 1.25597\tvalid_1's multi_logloss: 1.57316\n",
      "[770]\ttraining's multi_logloss: 1.25235\tvalid_1's multi_logloss: 1.57294\n",
      "[780]\ttraining's multi_logloss: 1.24878\tvalid_1's multi_logloss: 1.57275\n",
      "[790]\ttraining's multi_logloss: 1.24525\tvalid_1's multi_logloss: 1.57252\n",
      "[800]\ttraining's multi_logloss: 1.2417\tvalid_1's multi_logloss: 1.57232\n",
      "[810]\ttraining's multi_logloss: 1.23827\tvalid_1's multi_logloss: 1.57215\n",
      "[820]\ttraining's multi_logloss: 1.23484\tvalid_1's multi_logloss: 1.57197\n",
      "[830]\ttraining's multi_logloss: 1.23143\tvalid_1's multi_logloss: 1.57179\n",
      "[840]\ttraining's multi_logloss: 1.22795\tvalid_1's multi_logloss: 1.57163\n",
      "[850]\ttraining's multi_logloss: 1.22457\tvalid_1's multi_logloss: 1.57144\n",
      "[860]\ttraining's multi_logloss: 1.22121\tvalid_1's multi_logloss: 1.57125\n",
      "[870]\ttraining's multi_logloss: 1.21789\tvalid_1's multi_logloss: 1.5711\n",
      "[880]\ttraining's multi_logloss: 1.2146\tvalid_1's multi_logloss: 1.57095\n",
      "[890]\ttraining's multi_logloss: 1.21128\tvalid_1's multi_logloss: 1.57085\n",
      "[900]\ttraining's multi_logloss: 1.208\tvalid_1's multi_logloss: 1.57072\n",
      "[910]\ttraining's multi_logloss: 1.20477\tvalid_1's multi_logloss: 1.57055\n",
      "[920]\ttraining's multi_logloss: 1.20148\tvalid_1's multi_logloss: 1.57039\n",
      "[930]\ttraining's multi_logloss: 1.19826\tvalid_1's multi_logloss: 1.57026\n",
      "[940]\ttraining's multi_logloss: 1.19503\tvalid_1's multi_logloss: 1.57014\n",
      "[950]\ttraining's multi_logloss: 1.19185\tvalid_1's multi_logloss: 1.57003\n",
      "[960]\ttraining's multi_logloss: 1.18866\tvalid_1's multi_logloss: 1.56991\n",
      "[970]\ttraining's multi_logloss: 1.18556\tvalid_1's multi_logloss: 1.56981\n",
      "[980]\ttraining's multi_logloss: 1.18247\tvalid_1's multi_logloss: 1.56974\n",
      "[990]\ttraining's multi_logloss: 1.17934\tvalid_1's multi_logloss: 1.56966\n",
      "[1000]\ttraining's multi_logloss: 1.17629\tvalid_1's multi_logloss: 1.56959\n",
      "[1010]\ttraining's multi_logloss: 1.17324\tvalid_1's multi_logloss: 1.56951\n",
      "[1020]\ttraining's multi_logloss: 1.17022\tvalid_1's multi_logloss: 1.56944\n",
      "[1030]\ttraining's multi_logloss: 1.16716\tvalid_1's multi_logloss: 1.56938\n",
      "[1040]\ttraining's multi_logloss: 1.16408\tvalid_1's multi_logloss: 1.56929\n",
      "[1050]\ttraining's multi_logloss: 1.16114\tvalid_1's multi_logloss: 1.56923\n",
      "[1060]\ttraining's multi_logloss: 1.15818\tvalid_1's multi_logloss: 1.56914\n",
      "[1070]\ttraining's multi_logloss: 1.15524\tvalid_1's multi_logloss: 1.56912\n",
      "[1080]\ttraining's multi_logloss: 1.15233\tvalid_1's multi_logloss: 1.56906\n",
      "[1090]\ttraining's multi_logloss: 1.14943\tvalid_1's multi_logloss: 1.56898\n",
      "[1100]\ttraining's multi_logloss: 1.14649\tvalid_1's multi_logloss: 1.56893\n",
      "[1110]\ttraining's multi_logloss: 1.14355\tvalid_1's multi_logloss: 1.56891\n",
      "[1120]\ttraining's multi_logloss: 1.14069\tvalid_1's multi_logloss: 1.56887\n",
      "[1130]\ttraining's multi_logloss: 1.13787\tvalid_1's multi_logloss: 1.56881\n",
      "[1140]\ttraining's multi_logloss: 1.13501\tvalid_1's multi_logloss: 1.56876\n",
      "[1150]\ttraining's multi_logloss: 1.13216\tvalid_1's multi_logloss: 1.56877\n",
      "[1160]\ttraining's multi_logloss: 1.12931\tvalid_1's multi_logloss: 1.56868\n",
      "[1170]\ttraining's multi_logloss: 1.1265\tvalid_1's multi_logloss: 1.56863\n",
      "[1180]\ttraining's multi_logloss: 1.12369\tvalid_1's multi_logloss: 1.56859\n",
      "[1190]\ttraining's multi_logloss: 1.12096\tvalid_1's multi_logloss: 1.56861\n",
      "[1200]\ttraining's multi_logloss: 1.11822\tvalid_1's multi_logloss: 1.56858\n",
      "[1210]\ttraining's multi_logloss: 1.11542\tvalid_1's multi_logloss: 1.56853\n",
      "[1220]\ttraining's multi_logloss: 1.11266\tvalid_1's multi_logloss: 1.56854\n",
      "[1230]\ttraining's multi_logloss: 1.10996\tvalid_1's multi_logloss: 1.56855\n",
      "[1240]\ttraining's multi_logloss: 1.10728\tvalid_1's multi_logloss: 1.56853\n",
      "[1250]\ttraining's multi_logloss: 1.10463\tvalid_1's multi_logloss: 1.56856\n",
      "[1260]\ttraining's multi_logloss: 1.10199\tvalid_1's multi_logloss: 1.56854\n",
      "[1270]\ttraining's multi_logloss: 1.09927\tvalid_1's multi_logloss: 1.56856\n",
      "[1280]\ttraining's multi_logloss: 1.0966\tvalid_1's multi_logloss: 1.56856\n",
      "[1290]\ttraining's multi_logloss: 1.09393\tvalid_1's multi_logloss: 1.56852\n",
      "[1300]\ttraining's multi_logloss: 1.09137\tvalid_1's multi_logloss: 1.56854\n",
      "[1310]\ttraining's multi_logloss: 1.08872\tvalid_1's multi_logloss: 1.56854\n",
      "[1320]\ttraining's multi_logloss: 1.08611\tvalid_1's multi_logloss: 1.56856\n",
      "[1330]\ttraining's multi_logloss: 1.08352\tvalid_1's multi_logloss: 1.56857\n",
      "[1340]\ttraining's multi_logloss: 1.08092\tvalid_1's multi_logloss: 1.56859\n",
      "Early stopping, best iteration is:\n",
      "[1242]\ttraining's multi_logloss: 1.10678\tvalid_1's multi_logloss: 1.56852\n",
      "age************************************\n",
      "confusion_matrix is \n",
      " [[0.336 0.441 0.151 0.018 0.019 0.018 0.009 0.003 0.002 0.002]\n",
      " [0.027 0.493 0.386 0.043 0.029 0.013 0.005 0.002 0.001 0.001]\n",
      " [0.007 0.197 0.547 0.134 0.072 0.03  0.008 0.002 0.002 0.001]\n",
      " [0.003 0.064 0.436 0.251 0.163 0.059 0.015 0.004 0.004 0.001]\n",
      " [0.002 0.033 0.249 0.194 0.284 0.18  0.042 0.008 0.004 0.002]\n",
      " [0.003 0.022 0.162 0.121 0.283 0.282 0.1   0.017 0.007 0.004]\n",
      " [0.004 0.02  0.114 0.091 0.214 0.291 0.193 0.048 0.019 0.006]\n",
      " [0.004 0.017 0.103 0.069 0.147 0.212 0.226 0.127 0.076 0.02 ]\n",
      " [0.003 0.018 0.085 0.057 0.097 0.144 0.176 0.175 0.173 0.072]\n",
      " [0.003 0.012 0.072 0.039 0.058 0.09  0.094 0.114 0.23  0.289]] \n",
      " \n",
      "test acc is \n",
      " 0.3600055555555556 \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.34      0.44      6984\n",
      "           2       0.50      0.49      0.50     29861\n",
      "           3       0.37      0.55      0.44     40817\n",
      "           4       0.32      0.25      0.28     30045\n",
      "           5       0.28      0.28      0.28     26098\n",
      "           6       0.29      0.28      0.28     20240\n",
      "           7       0.28      0.19      0.23     13265\n",
      "           8       0.25      0.13      0.17      6331\n",
      "           9       0.28      0.17      0.21      3980\n",
      "          10       0.48      0.29      0.36      2379\n",
      "\n",
      "    accuracy                           0.36    180000\n",
      "   macro avg       0.37      0.30      0.32    180000\n",
      "weighted avg       0.36      0.36      0.35    180000\n",
      "\n",
      "accuracy is 36.000556 , sen is 0.336054,spe is 0.492582 \n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's binary_logloss: 0.55458\tvalid_1's binary_logloss: 0.555494\n",
      "[20]\ttraining's binary_logloss: 0.496011\tvalid_1's binary_logloss: 0.496965\n",
      "[30]\ttraining's binary_logloss: 0.455593\tvalid_1's binary_logloss: 0.456627\n",
      "[40]\ttraining's binary_logloss: 0.425141\tvalid_1's binary_logloss: 0.426142\n",
      "[50]\ttraining's binary_logloss: 0.402229\tvalid_1's binary_logloss: 0.403326\n",
      "[60]\ttraining's binary_logloss: 0.383399\tvalid_1's binary_logloss: 0.384575\n",
      "[70]\ttraining's binary_logloss: 0.36851\tvalid_1's binary_logloss: 0.369719\n",
      "[80]\ttraining's binary_logloss: 0.356434\tvalid_1's binary_logloss: 0.357744\n",
      "[90]\ttraining's binary_logloss: 0.346612\tvalid_1's binary_logloss: 0.347965\n",
      "[100]\ttraining's binary_logloss: 0.338169\tvalid_1's binary_logloss: 0.339603\n",
      "[110]\ttraining's binary_logloss: 0.331138\tvalid_1's binary_logloss: 0.332638\n",
      "[120]\ttraining's binary_logloss: 0.325295\tvalid_1's binary_logloss: 0.326858\n",
      "[130]\ttraining's binary_logloss: 0.320112\tvalid_1's binary_logloss: 0.321795\n",
      "[140]\ttraining's binary_logloss: 0.315581\tvalid_1's binary_logloss: 0.317415\n",
      "[150]\ttraining's binary_logloss: 0.311539\tvalid_1's binary_logloss: 0.313502\n",
      "[160]\ttraining's binary_logloss: 0.308029\tvalid_1's binary_logloss: 0.31011\n",
      "[170]\ttraining's binary_logloss: 0.304697\tvalid_1's binary_logloss: 0.306882\n",
      "[180]\ttraining's binary_logloss: 0.301735\tvalid_1's binary_logloss: 0.304047\n",
      "[190]\ttraining's binary_logloss: 0.299128\tvalid_1's binary_logloss: 0.301568\n",
      "[200]\ttraining's binary_logloss: 0.296764\tvalid_1's binary_logloss: 0.299347\n",
      "[210]\ttraining's binary_logloss: 0.294541\tvalid_1's binary_logloss: 0.297212\n",
      "[220]\ttraining's binary_logloss: 0.292469\tvalid_1's binary_logloss: 0.29527\n",
      "[230]\ttraining's binary_logloss: 0.290656\tvalid_1's binary_logloss: 0.293563\n",
      "[240]\ttraining's binary_logloss: 0.288924\tvalid_1's binary_logloss: 0.29193\n",
      "[250]\ttraining's binary_logloss: 0.287361\tvalid_1's binary_logloss: 0.290535\n",
      "[260]\ttraining's binary_logloss: 0.285839\tvalid_1's binary_logloss: 0.289138\n",
      "[270]\ttraining's binary_logloss: 0.284468\tvalid_1's binary_logloss: 0.287888\n",
      "[280]\ttraining's binary_logloss: 0.283128\tvalid_1's binary_logloss: 0.286669\n",
      "[290]\ttraining's binary_logloss: 0.281876\tvalid_1's binary_logloss: 0.285533\n",
      "[300]\ttraining's binary_logloss: 0.280686\tvalid_1's binary_logloss: 0.28448\n",
      "[310]\ttraining's binary_logloss: 0.279563\tvalid_1's binary_logloss: 0.28348\n",
      "[320]\ttraining's binary_logloss: 0.278502\tvalid_1's binary_logloss: 0.282532\n",
      "[330]\ttraining's binary_logloss: 0.277452\tvalid_1's binary_logloss: 0.281573\n",
      "[340]\ttraining's binary_logloss: 0.276478\tvalid_1's binary_logloss: 0.280737\n",
      "[350]\ttraining's binary_logloss: 0.275557\tvalid_1's binary_logloss: 0.279963\n",
      "[360]\ttraining's binary_logloss: 0.274616\tvalid_1's binary_logloss: 0.279142\n",
      "[370]\ttraining's binary_logloss: 0.273717\tvalid_1's binary_logloss: 0.27836\n",
      "[380]\ttraining's binary_logloss: 0.272883\tvalid_1's binary_logloss: 0.277645\n",
      "[390]\ttraining's binary_logloss: 0.272059\tvalid_1's binary_logloss: 0.276931\n",
      "[400]\ttraining's binary_logloss: 0.271309\tvalid_1's binary_logloss: 0.276312\n",
      "[410]\ttraining's binary_logloss: 0.270568\tvalid_1's binary_logloss: 0.275678\n",
      "[420]\ttraining's binary_logloss: 0.269879\tvalid_1's binary_logloss: 0.275111\n",
      "[430]\ttraining's binary_logloss: 0.269149\tvalid_1's binary_logloss: 0.274493\n",
      "[440]\ttraining's binary_logloss: 0.268486\tvalid_1's binary_logloss: 0.273958\n",
      "[450]\ttraining's binary_logloss: 0.267848\tvalid_1's binary_logloss: 0.273433\n",
      "[460]\ttraining's binary_logloss: 0.267201\tvalid_1's binary_logloss: 0.272899\n",
      "[470]\ttraining's binary_logloss: 0.266606\tvalid_1's binary_logloss: 0.272422\n",
      "[480]\ttraining's binary_logloss: 0.265977\tvalid_1's binary_logloss: 0.271908\n",
      "[490]\ttraining's binary_logloss: 0.265393\tvalid_1's binary_logloss: 0.271448\n",
      "[500]\ttraining's binary_logloss: 0.264812\tvalid_1's binary_logloss: 0.270999\n",
      "[510]\ttraining's binary_logloss: 0.264209\tvalid_1's binary_logloss: 0.270504\n",
      "[520]\ttraining's binary_logloss: 0.263652\tvalid_1's binary_logloss: 0.270068\n",
      "[530]\ttraining's binary_logloss: 0.263097\tvalid_1's binary_logloss: 0.269629\n",
      "[540]\ttraining's binary_logloss: 0.26257\tvalid_1's binary_logloss: 0.26923\n",
      "[550]\ttraining's binary_logloss: 0.262055\tvalid_1's binary_logloss: 0.268811\n",
      "[560]\ttraining's binary_logloss: 0.26155\tvalid_1's binary_logloss: 0.268421\n",
      "[570]\ttraining's binary_logloss: 0.261053\tvalid_1's binary_logloss: 0.268035\n",
      "[580]\ttraining's binary_logloss: 0.260556\tvalid_1's binary_logloss: 0.267661\n",
      "[590]\ttraining's binary_logloss: 0.260056\tvalid_1's binary_logloss: 0.267286\n",
      "[600]\ttraining's binary_logloss: 0.259576\tvalid_1's binary_logloss: 0.266919\n",
      "[610]\ttraining's binary_logloss: 0.259124\tvalid_1's binary_logloss: 0.266575\n",
      "[620]\ttraining's binary_logloss: 0.258679\tvalid_1's binary_logloss: 0.266251\n",
      "[630]\ttraining's binary_logloss: 0.258216\tvalid_1's binary_logloss: 0.265929\n",
      "[640]\ttraining's binary_logloss: 0.257815\tvalid_1's binary_logloss: 0.265655\n",
      "[650]\ttraining's binary_logloss: 0.257366\tvalid_1's binary_logloss: 0.265347\n",
      "[660]\ttraining's binary_logloss: 0.256946\tvalid_1's binary_logloss: 0.265035\n",
      "[670]\ttraining's binary_logloss: 0.256535\tvalid_1's binary_logloss: 0.264755\n",
      "[680]\ttraining's binary_logloss: 0.256129\tvalid_1's binary_logloss: 0.264509\n",
      "[690]\ttraining's binary_logloss: 0.255704\tvalid_1's binary_logloss: 0.264208\n",
      "[700]\ttraining's binary_logloss: 0.255296\tvalid_1's binary_logloss: 0.263929\n",
      "[710]\ttraining's binary_logloss: 0.254902\tvalid_1's binary_logloss: 0.263652\n",
      "[720]\ttraining's binary_logloss: 0.254518\tvalid_1's binary_logloss: 0.263408\n",
      "[730]\ttraining's binary_logloss: 0.254109\tvalid_1's binary_logloss: 0.263125\n",
      "[740]\ttraining's binary_logloss: 0.253735\tvalid_1's binary_logloss: 0.26289\n",
      "[750]\ttraining's binary_logloss: 0.253367\tvalid_1's binary_logloss: 0.262664\n",
      "[760]\ttraining's binary_logloss: 0.252997\tvalid_1's binary_logloss: 0.262427\n",
      "[770]\ttraining's binary_logloss: 0.252631\tvalid_1's binary_logloss: 0.262213\n",
      "[780]\ttraining's binary_logloss: 0.252265\tvalid_1's binary_logloss: 0.261965\n",
      "[790]\ttraining's binary_logloss: 0.251896\tvalid_1's binary_logloss: 0.261736\n",
      "[800]\ttraining's binary_logloss: 0.251557\tvalid_1's binary_logloss: 0.261502\n",
      "[810]\ttraining's binary_logloss: 0.251211\tvalid_1's binary_logloss: 0.261278\n",
      "[820]\ttraining's binary_logloss: 0.250856\tvalid_1's binary_logloss: 0.261061\n",
      "[830]\ttraining's binary_logloss: 0.250521\tvalid_1's binary_logloss: 0.260847\n",
      "[840]\ttraining's binary_logloss: 0.250164\tvalid_1's binary_logloss: 0.260652\n",
      "[850]\ttraining's binary_logloss: 0.249842\tvalid_1's binary_logloss: 0.260429\n",
      "[860]\ttraining's binary_logloss: 0.249483\tvalid_1's binary_logloss: 0.260227\n",
      "[870]\ttraining's binary_logloss: 0.249157\tvalid_1's binary_logloss: 0.26002\n",
      "[880]\ttraining's binary_logloss: 0.248829\tvalid_1's binary_logloss: 0.259844\n",
      "[890]\ttraining's binary_logloss: 0.248507\tvalid_1's binary_logloss: 0.259652\n",
      "[900]\ttraining's binary_logloss: 0.248187\tvalid_1's binary_logloss: 0.259469\n",
      "[910]\ttraining's binary_logloss: 0.247883\tvalid_1's binary_logloss: 0.259301\n",
      "[920]\ttraining's binary_logloss: 0.24757\tvalid_1's binary_logloss: 0.259109\n",
      "[930]\ttraining's binary_logloss: 0.247276\tvalid_1's binary_logloss: 0.258946\n",
      "[940]\ttraining's binary_logloss: 0.24697\tvalid_1's binary_logloss: 0.258757\n",
      "[950]\ttraining's binary_logloss: 0.246664\tvalid_1's binary_logloss: 0.258564\n",
      "[960]\ttraining's binary_logloss: 0.246367\tvalid_1's binary_logloss: 0.2584\n",
      "[970]\ttraining's binary_logloss: 0.246079\tvalid_1's binary_logloss: 0.258238\n",
      "[980]\ttraining's binary_logloss: 0.245788\tvalid_1's binary_logloss: 0.258065\n",
      "[990]\ttraining's binary_logloss: 0.245512\tvalid_1's binary_logloss: 0.257918\n",
      "[1000]\ttraining's binary_logloss: 0.245216\tvalid_1's binary_logloss: 0.257752\n",
      "[1010]\ttraining's binary_logloss: 0.244922\tvalid_1's binary_logloss: 0.257602\n",
      "[1020]\ttraining's binary_logloss: 0.244637\tvalid_1's binary_logloss: 0.257438\n",
      "[1030]\ttraining's binary_logloss: 0.244364\tvalid_1's binary_logloss: 0.25729\n",
      "[1040]\ttraining's binary_logloss: 0.244065\tvalid_1's binary_logloss: 0.257149\n",
      "[1050]\ttraining's binary_logloss: 0.243787\tvalid_1's binary_logloss: 0.256993\n",
      "[1060]\ttraining's binary_logloss: 0.243528\tvalid_1's binary_logloss: 0.256854\n",
      "[1070]\ttraining's binary_logloss: 0.243263\tvalid_1's binary_logloss: 0.256717\n",
      "[1080]\ttraining's binary_logloss: 0.24299\tvalid_1's binary_logloss: 0.256588\n",
      "[1090]\ttraining's binary_logloss: 0.242725\tvalid_1's binary_logloss: 0.256444\n",
      "[1100]\ttraining's binary_logloss: 0.242435\tvalid_1's binary_logloss: 0.256312\n",
      "[1110]\ttraining's binary_logloss: 0.242175\tvalid_1's binary_logloss: 0.256166\n",
      "[1120]\ttraining's binary_logloss: 0.241924\tvalid_1's binary_logloss: 0.256028\n",
      "[1130]\ttraining's binary_logloss: 0.241664\tvalid_1's binary_logloss: 0.255892\n",
      "[1140]\ttraining's binary_logloss: 0.241413\tvalid_1's binary_logloss: 0.255775\n",
      "[1150]\ttraining's binary_logloss: 0.241159\tvalid_1's binary_logloss: 0.255672\n",
      "[1160]\ttraining's binary_logloss: 0.240915\tvalid_1's binary_logloss: 0.255575\n",
      "[1170]\ttraining's binary_logloss: 0.240666\tvalid_1's binary_logloss: 0.255431\n",
      "[1180]\ttraining's binary_logloss: 0.240423\tvalid_1's binary_logloss: 0.25531\n",
      "[1190]\ttraining's binary_logloss: 0.240175\tvalid_1's binary_logloss: 0.255198\n",
      "[1200]\ttraining's binary_logloss: 0.239907\tvalid_1's binary_logloss: 0.255095\n",
      "[1210]\ttraining's binary_logloss: 0.239667\tvalid_1's binary_logloss: 0.254959\n",
      "[1220]\ttraining's binary_logloss: 0.239411\tvalid_1's binary_logloss: 0.254838\n",
      "[1230]\ttraining's binary_logloss: 0.239164\tvalid_1's binary_logloss: 0.254738\n",
      "[1240]\ttraining's binary_logloss: 0.238937\tvalid_1's binary_logloss: 0.25464\n",
      "[1250]\ttraining's binary_logloss: 0.238715\tvalid_1's binary_logloss: 0.254549\n",
      "[1260]\ttraining's binary_logloss: 0.238493\tvalid_1's binary_logloss: 0.254451\n",
      "[1270]\ttraining's binary_logloss: 0.238266\tvalid_1's binary_logloss: 0.254342\n",
      "[1280]\ttraining's binary_logloss: 0.238035\tvalid_1's binary_logloss: 0.254233\n",
      "[1290]\ttraining's binary_logloss: 0.237801\tvalid_1's binary_logloss: 0.254123\n",
      "[1300]\ttraining's binary_logloss: 0.23758\tvalid_1's binary_logloss: 0.254034\n",
      "[1310]\ttraining's binary_logloss: 0.237356\tvalid_1's binary_logloss: 0.253921\n",
      "[1320]\ttraining's binary_logloss: 0.237124\tvalid_1's binary_logloss: 0.253835\n",
      "[1330]\ttraining's binary_logloss: 0.236897\tvalid_1's binary_logloss: 0.253735\n",
      "[1340]\ttraining's binary_logloss: 0.236668\tvalid_1's binary_logloss: 0.253645\n",
      "[1350]\ttraining's binary_logloss: 0.236447\tvalid_1's binary_logloss: 0.253537\n",
      "[1360]\ttraining's binary_logloss: 0.236229\tvalid_1's binary_logloss: 0.253446\n",
      "[1370]\ttraining's binary_logloss: 0.236023\tvalid_1's binary_logloss: 0.25337\n",
      "[1380]\ttraining's binary_logloss: 0.2358\tvalid_1's binary_logloss: 0.253289\n",
      "[1390]\ttraining's binary_logloss: 0.235595\tvalid_1's binary_logloss: 0.253197\n",
      "[1400]\ttraining's binary_logloss: 0.23537\tvalid_1's binary_logloss: 0.253106\n",
      "[1410]\ttraining's binary_logloss: 0.235161\tvalid_1's binary_logloss: 0.253039\n",
      "[1420]\ttraining's binary_logloss: 0.234948\tvalid_1's binary_logloss: 0.252973\n",
      "[1430]\ttraining's binary_logloss: 0.234753\tvalid_1's binary_logloss: 0.252906\n",
      "[1440]\ttraining's binary_logloss: 0.23454\tvalid_1's binary_logloss: 0.252816\n",
      "[1450]\ttraining's binary_logloss: 0.234341\tvalid_1's binary_logloss: 0.252755\n",
      "[1460]\ttraining's binary_logloss: 0.23414\tvalid_1's binary_logloss: 0.252682\n",
      "[1470]\ttraining's binary_logloss: 0.233947\tvalid_1's binary_logloss: 0.252597\n",
      "[1480]\ttraining's binary_logloss: 0.233759\tvalid_1's binary_logloss: 0.252519\n",
      "[1490]\ttraining's binary_logloss: 0.233541\tvalid_1's binary_logloss: 0.252446\n",
      "[1500]\ttraining's binary_logloss: 0.233344\tvalid_1's binary_logloss: 0.252377\n",
      "[1510]\ttraining's binary_logloss: 0.233142\tvalid_1's binary_logloss: 0.252308\n",
      "[1520]\ttraining's binary_logloss: 0.232946\tvalid_1's binary_logloss: 0.252239\n",
      "[1530]\ttraining's binary_logloss: 0.232756\tvalid_1's binary_logloss: 0.252161\n",
      "[1540]\ttraining's binary_logloss: 0.232555\tvalid_1's binary_logloss: 0.252089\n",
      "[1550]\ttraining's binary_logloss: 0.232345\tvalid_1's binary_logloss: 0.25204\n",
      "[1560]\ttraining's binary_logloss: 0.232157\tvalid_1's binary_logloss: 0.251969\n",
      "[1570]\ttraining's binary_logloss: 0.231955\tvalid_1's binary_logloss: 0.251905\n",
      "[1580]\ttraining's binary_logloss: 0.231771\tvalid_1's binary_logloss: 0.251836\n",
      "[1590]\ttraining's binary_logloss: 0.231587\tvalid_1's binary_logloss: 0.251763\n",
      "[1600]\ttraining's binary_logloss: 0.231407\tvalid_1's binary_logloss: 0.251705\n",
      "[1610]\ttraining's binary_logloss: 0.231228\tvalid_1's binary_logloss: 0.251657\n",
      "[1620]\ttraining's binary_logloss: 0.231018\tvalid_1's binary_logloss: 0.251591\n",
      "[1630]\ttraining's binary_logloss: 0.23082\tvalid_1's binary_logloss: 0.25154\n",
      "[1640]\ttraining's binary_logloss: 0.230644\tvalid_1's binary_logloss: 0.251489\n",
      "[1650]\ttraining's binary_logloss: 0.23046\tvalid_1's binary_logloss: 0.251438\n",
      "[1660]\ttraining's binary_logloss: 0.230272\tvalid_1's binary_logloss: 0.251382\n",
      "[1670]\ttraining's binary_logloss: 0.230087\tvalid_1's binary_logloss: 0.251324\n",
      "[1680]\ttraining's binary_logloss: 0.229895\tvalid_1's binary_logloss: 0.251235\n",
      "[1690]\ttraining's binary_logloss: 0.229711\tvalid_1's binary_logloss: 0.251164\n",
      "[1700]\ttraining's binary_logloss: 0.229536\tvalid_1's binary_logloss: 0.251122\n",
      "[1710]\ttraining's binary_logloss: 0.229372\tvalid_1's binary_logloss: 0.251108\n",
      "[1720]\ttraining's binary_logloss: 0.229197\tvalid_1's binary_logloss: 0.251059\n",
      "[1730]\ttraining's binary_logloss: 0.229036\tvalid_1's binary_logloss: 0.251011\n",
      "[1740]\ttraining's binary_logloss: 0.228858\tvalid_1's binary_logloss: 0.250962\n",
      "[1750]\ttraining's binary_logloss: 0.228683\tvalid_1's binary_logloss: 0.25092\n",
      "[1760]\ttraining's binary_logloss: 0.22852\tvalid_1's binary_logloss: 0.250896\n",
      "[1770]\ttraining's binary_logloss: 0.228353\tvalid_1's binary_logloss: 0.25085\n",
      "[1780]\ttraining's binary_logloss: 0.228167\tvalid_1's binary_logloss: 0.2508\n",
      "[1790]\ttraining's binary_logloss: 0.227996\tvalid_1's binary_logloss: 0.250742\n",
      "[1800]\ttraining's binary_logloss: 0.22784\tvalid_1's binary_logloss: 0.25071\n",
      "[1810]\ttraining's binary_logloss: 0.227678\tvalid_1's binary_logloss: 0.250666\n",
      "[1820]\ttraining's binary_logloss: 0.227512\tvalid_1's binary_logloss: 0.250645\n",
      "[1830]\ttraining's binary_logloss: 0.227351\tvalid_1's binary_logloss: 0.25061\n",
      "[1840]\ttraining's binary_logloss: 0.227181\tvalid_1's binary_logloss: 0.250555\n",
      "[1850]\ttraining's binary_logloss: 0.227026\tvalid_1's binary_logloss: 0.250517\n",
      "[1860]\ttraining's binary_logloss: 0.226861\tvalid_1's binary_logloss: 0.250489\n",
      "[1870]\ttraining's binary_logloss: 0.226686\tvalid_1's binary_logloss: 0.250442\n",
      "[1880]\ttraining's binary_logloss: 0.226513\tvalid_1's binary_logloss: 0.250406\n",
      "[1890]\ttraining's binary_logloss: 0.226335\tvalid_1's binary_logloss: 0.250365\n",
      "[1900]\ttraining's binary_logloss: 0.226169\tvalid_1's binary_logloss: 0.250319\n",
      "[1910]\ttraining's binary_logloss: 0.226003\tvalid_1's binary_logloss: 0.250295\n",
      "[1920]\ttraining's binary_logloss: 0.22585\tvalid_1's binary_logloss: 0.250263\n",
      "[1930]\ttraining's binary_logloss: 0.225684\tvalid_1's binary_logloss: 0.250225\n",
      "[1940]\ttraining's binary_logloss: 0.225521\tvalid_1's binary_logloss: 0.250176\n",
      "[1950]\ttraining's binary_logloss: 0.225361\tvalid_1's binary_logloss: 0.250143\n",
      "[1960]\ttraining's binary_logloss: 0.2252\tvalid_1's binary_logloss: 0.250113\n",
      "[1970]\ttraining's binary_logloss: 0.225041\tvalid_1's binary_logloss: 0.250073\n",
      "[1980]\ttraining's binary_logloss: 0.224869\tvalid_1's binary_logloss: 0.250051\n",
      "[1990]\ttraining's binary_logloss: 0.224718\tvalid_1's binary_logloss: 0.250029\n",
      "[2000]\ttraining's binary_logloss: 0.224568\tvalid_1's binary_logloss: 0.249993\n",
      "[2010]\ttraining's binary_logloss: 0.224404\tvalid_1's binary_logloss: 0.249963\n",
      "[2020]\ttraining's binary_logloss: 0.224235\tvalid_1's binary_logloss: 0.249929\n",
      "[2030]\ttraining's binary_logloss: 0.224086\tvalid_1's binary_logloss: 0.249912\n",
      "[2040]\ttraining's binary_logloss: 0.223921\tvalid_1's binary_logloss: 0.249892\n",
      "[2050]\ttraining's binary_logloss: 0.22377\tvalid_1's binary_logloss: 0.249872\n",
      "[2060]\ttraining's binary_logloss: 0.223611\tvalid_1's binary_logloss: 0.249845\n",
      "[2070]\ttraining's binary_logloss: 0.22346\tvalid_1's binary_logloss: 0.249813\n",
      "[2080]\ttraining's binary_logloss: 0.223295\tvalid_1's binary_logloss: 0.249772\n",
      "[2090]\ttraining's binary_logloss: 0.223142\tvalid_1's binary_logloss: 0.249746\n",
      "[2100]\ttraining's binary_logloss: 0.223006\tvalid_1's binary_logloss: 0.249736\n",
      "[2110]\ttraining's binary_logloss: 0.222853\tvalid_1's binary_logloss: 0.249705\n",
      "[2120]\ttraining's binary_logloss: 0.222689\tvalid_1's binary_logloss: 0.249666\n",
      "[2130]\ttraining's binary_logloss: 0.222536\tvalid_1's binary_logloss: 0.24963\n",
      "[2140]\ttraining's binary_logloss: 0.222378\tvalid_1's binary_logloss: 0.249603\n",
      "[2150]\ttraining's binary_logloss: 0.222239\tvalid_1's binary_logloss: 0.249589\n",
      "[2160]\ttraining's binary_logloss: 0.222097\tvalid_1's binary_logloss: 0.24957\n",
      "[2170]\ttraining's binary_logloss: 0.221946\tvalid_1's binary_logloss: 0.249536\n",
      "[2180]\ttraining's binary_logloss: 0.221807\tvalid_1's binary_logloss: 0.249518\n",
      "[2190]\ttraining's binary_logloss: 0.221677\tvalid_1's binary_logloss: 0.249486\n",
      "[2200]\ttraining's binary_logloss: 0.221519\tvalid_1's binary_logloss: 0.249443\n",
      "[2210]\ttraining's binary_logloss: 0.221383\tvalid_1's binary_logloss: 0.249416\n",
      "[2220]\ttraining's binary_logloss: 0.221238\tvalid_1's binary_logloss: 0.249392\n",
      "[2230]\ttraining's binary_logloss: 0.221089\tvalid_1's binary_logloss: 0.249357\n",
      "[2240]\ttraining's binary_logloss: 0.220945\tvalid_1's binary_logloss: 0.249324\n",
      "[2250]\ttraining's binary_logloss: 0.22079\tvalid_1's binary_logloss: 0.2493\n",
      "[2260]\ttraining's binary_logloss: 0.220643\tvalid_1's binary_logloss: 0.249273\n",
      "[2270]\ttraining's binary_logloss: 0.220508\tvalid_1's binary_logloss: 0.249253\n",
      "[2280]\ttraining's binary_logloss: 0.220371\tvalid_1's binary_logloss: 0.249231\n",
      "[2290]\ttraining's binary_logloss: 0.220223\tvalid_1's binary_logloss: 0.249217\n",
      "[2300]\ttraining's binary_logloss: 0.22009\tvalid_1's binary_logloss: 0.249197\n",
      "[2310]\ttraining's binary_logloss: 0.219954\tvalid_1's binary_logloss: 0.249166\n",
      "[2320]\ttraining's binary_logloss: 0.219809\tvalid_1's binary_logloss: 0.24915\n",
      "[2330]\ttraining's binary_logloss: 0.219668\tvalid_1's binary_logloss: 0.249124\n",
      "[2340]\ttraining's binary_logloss: 0.219538\tvalid_1's binary_logloss: 0.249103\n",
      "[2350]\ttraining's binary_logloss: 0.219402\tvalid_1's binary_logloss: 0.249082\n",
      "[2360]\ttraining's binary_logloss: 0.219249\tvalid_1's binary_logloss: 0.249054\n",
      "[2370]\ttraining's binary_logloss: 0.21911\tvalid_1's binary_logloss: 0.249036\n",
      "[2380]\ttraining's binary_logloss: 0.21898\tvalid_1's binary_logloss: 0.249019\n",
      "[2390]\ttraining's binary_logloss: 0.218847\tvalid_1's binary_logloss: 0.249003\n",
      "[2400]\ttraining's binary_logloss: 0.218693\tvalid_1's binary_logloss: 0.248977\n",
      "[2410]\ttraining's binary_logloss: 0.218538\tvalid_1's binary_logloss: 0.248939\n",
      "[2420]\ttraining's binary_logloss: 0.218389\tvalid_1's binary_logloss: 0.248903\n",
      "[2430]\ttraining's binary_logloss: 0.21826\tvalid_1's binary_logloss: 0.24889\n",
      "[2440]\ttraining's binary_logloss: 0.218125\tvalid_1's binary_logloss: 0.24888\n",
      "[2450]\ttraining's binary_logloss: 0.217969\tvalid_1's binary_logloss: 0.248853\n",
      "[2460]\ttraining's binary_logloss: 0.21784\tvalid_1's binary_logloss: 0.248836\n",
      "[2470]\ttraining's binary_logloss: 0.217701\tvalid_1's binary_logloss: 0.248807\n",
      "[2480]\ttraining's binary_logloss: 0.217563\tvalid_1's binary_logloss: 0.248789\n",
      "[2490]\ttraining's binary_logloss: 0.217424\tvalid_1's binary_logloss: 0.248765\n",
      "[2500]\ttraining's binary_logloss: 0.217283\tvalid_1's binary_logloss: 0.248732\n",
      "[2510]\ttraining's binary_logloss: 0.217146\tvalid_1's binary_logloss: 0.248722\n",
      "[2520]\ttraining's binary_logloss: 0.217016\tvalid_1's binary_logloss: 0.24871\n",
      "[2530]\ttraining's binary_logloss: 0.216869\tvalid_1's binary_logloss: 0.248684\n",
      "[2540]\ttraining's binary_logloss: 0.216742\tvalid_1's binary_logloss: 0.248683\n",
      "[2550]\ttraining's binary_logloss: 0.216601\tvalid_1's binary_logloss: 0.248662\n",
      "[2560]\ttraining's binary_logloss: 0.216461\tvalid_1's binary_logloss: 0.248634\n",
      "[2570]\ttraining's binary_logloss: 0.216324\tvalid_1's binary_logloss: 0.248616\n",
      "[2580]\ttraining's binary_logloss: 0.216188\tvalid_1's binary_logloss: 0.248611\n",
      "[2590]\ttraining's binary_logloss: 0.21606\tvalid_1's binary_logloss: 0.2486\n",
      "[2600]\ttraining's binary_logloss: 0.215936\tvalid_1's binary_logloss: 0.248591\n",
      "[2610]\ttraining's binary_logloss: 0.215789\tvalid_1's binary_logloss: 0.248565\n",
      "[2620]\ttraining's binary_logloss: 0.215654\tvalid_1's binary_logloss: 0.24854\n",
      "[2630]\ttraining's binary_logloss: 0.215526\tvalid_1's binary_logloss: 0.248527\n",
      "[2640]\ttraining's binary_logloss: 0.215417\tvalid_1's binary_logloss: 0.248518\n",
      "[2650]\ttraining's binary_logloss: 0.215284\tvalid_1's binary_logloss: 0.248505\n",
      "[2660]\ttraining's binary_logloss: 0.215154\tvalid_1's binary_logloss: 0.248487\n",
      "[2670]\ttraining's binary_logloss: 0.21503\tvalid_1's binary_logloss: 0.248475\n",
      "[2680]\ttraining's binary_logloss: 0.214867\tvalid_1's binary_logloss: 0.248432\n",
      "[2690]\ttraining's binary_logloss: 0.214737\tvalid_1's binary_logloss: 0.248427\n",
      "[2700]\ttraining's binary_logloss: 0.214611\tvalid_1's binary_logloss: 0.248426\n",
      "[2710]\ttraining's binary_logloss: 0.214474\tvalid_1's binary_logloss: 0.248404\n",
      "[2720]\ttraining's binary_logloss: 0.214331\tvalid_1's binary_logloss: 0.248394\n",
      "[2730]\ttraining's binary_logloss: 0.214191\tvalid_1's binary_logloss: 0.248367\n",
      "[2740]\ttraining's binary_logloss: 0.214054\tvalid_1's binary_logloss: 0.248345\n",
      "[2750]\ttraining's binary_logloss: 0.213914\tvalid_1's binary_logloss: 0.248319\n",
      "[2760]\ttraining's binary_logloss: 0.213784\tvalid_1's binary_logloss: 0.248305\n",
      "[2770]\ttraining's binary_logloss: 0.213646\tvalid_1's binary_logloss: 0.248275\n",
      "[2780]\ttraining's binary_logloss: 0.213526\tvalid_1's binary_logloss: 0.248256\n",
      "[2790]\ttraining's binary_logloss: 0.213397\tvalid_1's binary_logloss: 0.248237\n",
      "[2800]\ttraining's binary_logloss: 0.213264\tvalid_1's binary_logloss: 0.248218\n",
      "[2810]\ttraining's binary_logloss: 0.213133\tvalid_1's binary_logloss: 0.2482\n",
      "[2820]\ttraining's binary_logloss: 0.212997\tvalid_1's binary_logloss: 0.248183\n",
      "[2830]\ttraining's binary_logloss: 0.212868\tvalid_1's binary_logloss: 0.248161\n",
      "[2840]\ttraining's binary_logloss: 0.212728\tvalid_1's binary_logloss: 0.248145\n",
      "[2850]\ttraining's binary_logloss: 0.212607\tvalid_1's binary_logloss: 0.248137\n",
      "[2860]\ttraining's binary_logloss: 0.212482\tvalid_1's binary_logloss: 0.248125\n",
      "[2870]\ttraining's binary_logloss: 0.212353\tvalid_1's binary_logloss: 0.248111\n",
      "[2880]\ttraining's binary_logloss: 0.212224\tvalid_1's binary_logloss: 0.248103\n",
      "[2890]\ttraining's binary_logloss: 0.212107\tvalid_1's binary_logloss: 0.248086\n",
      "[2900]\ttraining's binary_logloss: 0.211992\tvalid_1's binary_logloss: 0.248071\n",
      "[2910]\ttraining's binary_logloss: 0.211868\tvalid_1's binary_logloss: 0.248054\n",
      "[2920]\ttraining's binary_logloss: 0.211736\tvalid_1's binary_logloss: 0.248041\n",
      "[2930]\ttraining's binary_logloss: 0.211597\tvalid_1's binary_logloss: 0.24803\n",
      "[2940]\ttraining's binary_logloss: 0.211484\tvalid_1's binary_logloss: 0.248023\n",
      "[2950]\ttraining's binary_logloss: 0.211371\tvalid_1's binary_logloss: 0.248014\n",
      "[2960]\ttraining's binary_logloss: 0.211246\tvalid_1's binary_logloss: 0.247996\n",
      "[2970]\ttraining's binary_logloss: 0.21112\tvalid_1's binary_logloss: 0.247981\n",
      "[2980]\ttraining's binary_logloss: 0.211015\tvalid_1's binary_logloss: 0.247965\n",
      "[2990]\ttraining's binary_logloss: 0.210891\tvalid_1's binary_logloss: 0.247941\n",
      "[3000]\ttraining's binary_logloss: 0.210758\tvalid_1's binary_logloss: 0.247927\n",
      "[3010]\ttraining's binary_logloss: 0.210627\tvalid_1's binary_logloss: 0.247905\n",
      "[3020]\ttraining's binary_logloss: 0.210487\tvalid_1's binary_logloss: 0.247891\n",
      "[3030]\ttraining's binary_logloss: 0.210371\tvalid_1's binary_logloss: 0.247878\n",
      "[3040]\ttraining's binary_logloss: 0.210243\tvalid_1's binary_logloss: 0.247854\n",
      "[3050]\ttraining's binary_logloss: 0.21011\tvalid_1's binary_logloss: 0.247847\n",
      "[3060]\ttraining's binary_logloss: 0.209974\tvalid_1's binary_logloss: 0.247827\n",
      "[3070]\ttraining's binary_logloss: 0.209866\tvalid_1's binary_logloss: 0.247812\n",
      "[3080]\ttraining's binary_logloss: 0.209758\tvalid_1's binary_logloss: 0.247807\n",
      "[3090]\ttraining's binary_logloss: 0.209645\tvalid_1's binary_logloss: 0.247799\n",
      "[3100]\ttraining's binary_logloss: 0.209527\tvalid_1's binary_logloss: 0.247785\n",
      "[3110]\ttraining's binary_logloss: 0.209393\tvalid_1's binary_logloss: 0.247767\n",
      "[3120]\ttraining's binary_logloss: 0.209273\tvalid_1's binary_logloss: 0.247757\n",
      "[3130]\ttraining's binary_logloss: 0.209152\tvalid_1's binary_logloss: 0.247741\n",
      "[3140]\ttraining's binary_logloss: 0.209045\tvalid_1's binary_logloss: 0.24774\n",
      "[3150]\ttraining's binary_logloss: 0.208933\tvalid_1's binary_logloss: 0.247725\n",
      "[3160]\ttraining's binary_logloss: 0.208803\tvalid_1's binary_logloss: 0.247688\n",
      "[3170]\ttraining's binary_logloss: 0.208666\tvalid_1's binary_logloss: 0.247664\n",
      "[3180]\ttraining's binary_logloss: 0.208543\tvalid_1's binary_logloss: 0.247654\n",
      "[3190]\ttraining's binary_logloss: 0.208417\tvalid_1's binary_logloss: 0.247636\n",
      "[3200]\ttraining's binary_logloss: 0.208296\tvalid_1's binary_logloss: 0.247625\n",
      "[3210]\ttraining's binary_logloss: 0.208184\tvalid_1's binary_logloss: 0.247618\n",
      "[3220]\ttraining's binary_logloss: 0.208053\tvalid_1's binary_logloss: 0.247608\n",
      "[3230]\ttraining's binary_logloss: 0.207927\tvalid_1's binary_logloss: 0.247601\n",
      "[3240]\ttraining's binary_logloss: 0.207805\tvalid_1's binary_logloss: 0.247597\n",
      "[3250]\ttraining's binary_logloss: 0.207659\tvalid_1's binary_logloss: 0.247569\n",
      "[3260]\ttraining's binary_logloss: 0.207538\tvalid_1's binary_logloss: 0.247554\n",
      "[3270]\ttraining's binary_logloss: 0.207429\tvalid_1's binary_logloss: 0.247534\n",
      "[3280]\ttraining's binary_logloss: 0.207315\tvalid_1's binary_logloss: 0.24752\n",
      "[3290]\ttraining's binary_logloss: 0.207192\tvalid_1's binary_logloss: 0.247504\n",
      "[3300]\ttraining's binary_logloss: 0.207082\tvalid_1's binary_logloss: 0.24749\n",
      "[3310]\ttraining's binary_logloss: 0.206967\tvalid_1's binary_logloss: 0.247478\n",
      "[3320]\ttraining's binary_logloss: 0.206846\tvalid_1's binary_logloss: 0.247459\n",
      "[3330]\ttraining's binary_logloss: 0.206742\tvalid_1's binary_logloss: 0.247451\n",
      "[3340]\ttraining's binary_logloss: 0.206624\tvalid_1's binary_logloss: 0.247433\n",
      "[3350]\ttraining's binary_logloss: 0.206509\tvalid_1's binary_logloss: 0.247428\n",
      "[3360]\ttraining's binary_logloss: 0.206383\tvalid_1's binary_logloss: 0.247414\n",
      "[3370]\ttraining's binary_logloss: 0.206275\tvalid_1's binary_logloss: 0.247397\n",
      "[3380]\ttraining's binary_logloss: 0.206149\tvalid_1's binary_logloss: 0.247379\n",
      "[3390]\ttraining's binary_logloss: 0.206025\tvalid_1's binary_logloss: 0.247362\n",
      "[3400]\ttraining's binary_logloss: 0.20591\tvalid_1's binary_logloss: 0.247354\n",
      "[3410]\ttraining's binary_logloss: 0.205795\tvalid_1's binary_logloss: 0.247337\n",
      "[3420]\ttraining's binary_logloss: 0.205673\tvalid_1's binary_logloss: 0.247331\n",
      "[3430]\ttraining's binary_logloss: 0.205567\tvalid_1's binary_logloss: 0.247324\n",
      "[3440]\ttraining's binary_logloss: 0.20546\tvalid_1's binary_logloss: 0.247323\n",
      "[3450]\ttraining's binary_logloss: 0.205356\tvalid_1's binary_logloss: 0.247315\n",
      "[3460]\ttraining's binary_logloss: 0.205236\tvalid_1's binary_logloss: 0.2473\n",
      "[3470]\ttraining's binary_logloss: 0.205126\tvalid_1's binary_logloss: 0.247297\n",
      "[3480]\ttraining's binary_logloss: 0.205014\tvalid_1's binary_logloss: 0.247297\n",
      "[3490]\ttraining's binary_logloss: 0.204896\tvalid_1's binary_logloss: 0.247291\n",
      "[3500]\ttraining's binary_logloss: 0.204785\tvalid_1's binary_logloss: 0.24728\n",
      "[3510]\ttraining's binary_logloss: 0.20467\tvalid_1's binary_logloss: 0.247273\n",
      "[3520]\ttraining's binary_logloss: 0.204553\tvalid_1's binary_logloss: 0.247262\n",
      "[3530]\ttraining's binary_logloss: 0.204436\tvalid_1's binary_logloss: 0.247252\n",
      "[3540]\ttraining's binary_logloss: 0.204313\tvalid_1's binary_logloss: 0.247242\n",
      "[3550]\ttraining's binary_logloss: 0.204175\tvalid_1's binary_logloss: 0.247211\n",
      "[3560]\ttraining's binary_logloss: 0.204063\tvalid_1's binary_logloss: 0.247196\n",
      "[3570]\ttraining's binary_logloss: 0.203949\tvalid_1's binary_logloss: 0.247195\n",
      "[3580]\ttraining's binary_logloss: 0.20382\tvalid_1's binary_logloss: 0.247177\n",
      "[3590]\ttraining's binary_logloss: 0.203693\tvalid_1's binary_logloss: 0.247157\n",
      "[3600]\ttraining's binary_logloss: 0.203587\tvalid_1's binary_logloss: 0.24715\n",
      "[3610]\ttraining's binary_logloss: 0.203477\tvalid_1's binary_logloss: 0.247141\n",
      "[3620]\ttraining's binary_logloss: 0.203375\tvalid_1's binary_logloss: 0.247137\n",
      "[3630]\ttraining's binary_logloss: 0.203268\tvalid_1's binary_logloss: 0.247127\n",
      "[3640]\ttraining's binary_logloss: 0.203148\tvalid_1's binary_logloss: 0.247115\n",
      "[3650]\ttraining's binary_logloss: 0.203039\tvalid_1's binary_logloss: 0.247105\n",
      "[3660]\ttraining's binary_logloss: 0.202917\tvalid_1's binary_logloss: 0.24709\n",
      "[3670]\ttraining's binary_logloss: 0.20281\tvalid_1's binary_logloss: 0.247075\n",
      "[3680]\ttraining's binary_logloss: 0.2027\tvalid_1's binary_logloss: 0.247064\n",
      "[3690]\ttraining's binary_logloss: 0.202588\tvalid_1's binary_logloss: 0.247054\n",
      "[3700]\ttraining's binary_logloss: 0.202486\tvalid_1's binary_logloss: 0.247047\n",
      "[3710]\ttraining's binary_logloss: 0.202373\tvalid_1's binary_logloss: 0.247044\n",
      "[3720]\ttraining's binary_logloss: 0.202261\tvalid_1's binary_logloss: 0.247023\n",
      "[3730]\ttraining's binary_logloss: 0.202142\tvalid_1's binary_logloss: 0.247004\n",
      "[3740]\ttraining's binary_logloss: 0.202028\tvalid_1's binary_logloss: 0.246993\n",
      "[3750]\ttraining's binary_logloss: 0.201917\tvalid_1's binary_logloss: 0.246981\n",
      "[3760]\ttraining's binary_logloss: 0.201815\tvalid_1's binary_logloss: 0.24697\n",
      "[3770]\ttraining's binary_logloss: 0.201707\tvalid_1's binary_logloss: 0.246967\n",
      "[3780]\ttraining's binary_logloss: 0.201578\tvalid_1's binary_logloss: 0.246937\n",
      "[3790]\ttraining's binary_logloss: 0.201477\tvalid_1's binary_logloss: 0.246931\n",
      "[3800]\ttraining's binary_logloss: 0.201375\tvalid_1's binary_logloss: 0.246938\n",
      "[3810]\ttraining's binary_logloss: 0.201268\tvalid_1's binary_logloss: 0.246929\n",
      "[3820]\ttraining's binary_logloss: 0.201166\tvalid_1's binary_logloss: 0.246918\n",
      "[3830]\ttraining's binary_logloss: 0.201045\tvalid_1's binary_logloss: 0.246897\n",
      "[3840]\ttraining's binary_logloss: 0.200942\tvalid_1's binary_logloss: 0.246887\n",
      "[3850]\ttraining's binary_logloss: 0.20084\tvalid_1's binary_logloss: 0.246883\n",
      "[3860]\ttraining's binary_logloss: 0.200734\tvalid_1's binary_logloss: 0.246871\n",
      "[3870]\ttraining's binary_logloss: 0.20062\tvalid_1's binary_logloss: 0.246859\n",
      "[3880]\ttraining's binary_logloss: 0.200503\tvalid_1's binary_logloss: 0.246846\n",
      "[3890]\ttraining's binary_logloss: 0.2004\tvalid_1's binary_logloss: 0.246834\n",
      "[3900]\ttraining's binary_logloss: 0.200289\tvalid_1's binary_logloss: 0.246828\n",
      "[3910]\ttraining's binary_logloss: 0.20019\tvalid_1's binary_logloss: 0.246827\n",
      "[3920]\ttraining's binary_logloss: 0.200092\tvalid_1's binary_logloss: 0.246835\n",
      "[3930]\ttraining's binary_logloss: 0.199977\tvalid_1's binary_logloss: 0.246815\n",
      "[3940]\ttraining's binary_logloss: 0.199866\tvalid_1's binary_logloss: 0.246804\n",
      "[3950]\ttraining's binary_logloss: 0.199763\tvalid_1's binary_logloss: 0.246794\n",
      "[3960]\ttraining's binary_logloss: 0.199653\tvalid_1's binary_logloss: 0.246783\n",
      "[3970]\ttraining's binary_logloss: 0.199536\tvalid_1's binary_logloss: 0.246768\n",
      "[3980]\ttraining's binary_logloss: 0.199416\tvalid_1's binary_logloss: 0.246755\n",
      "[3990]\ttraining's binary_logloss: 0.199313\tvalid_1's binary_logloss: 0.246747\n",
      "[4000]\ttraining's binary_logloss: 0.199184\tvalid_1's binary_logloss: 0.246725\n",
      "[4010]\ttraining's binary_logloss: 0.19908\tvalid_1's binary_logloss: 0.246713\n",
      "[4020]\ttraining's binary_logloss: 0.198972\tvalid_1's binary_logloss: 0.246701\n",
      "[4030]\ttraining's binary_logloss: 0.198847\tvalid_1's binary_logloss: 0.246681\n",
      "[4040]\ttraining's binary_logloss: 0.198713\tvalid_1's binary_logloss: 0.246666\n",
      "[4050]\ttraining's binary_logloss: 0.198601\tvalid_1's binary_logloss: 0.246656\n",
      "[4060]\ttraining's binary_logloss: 0.198486\tvalid_1's binary_logloss: 0.246629\n",
      "[4070]\ttraining's binary_logloss: 0.198389\tvalid_1's binary_logloss: 0.246622\n",
      "[4080]\ttraining's binary_logloss: 0.198276\tvalid_1's binary_logloss: 0.246607\n",
      "[4090]\ttraining's binary_logloss: 0.198171\tvalid_1's binary_logloss: 0.246601\n",
      "[4100]\ttraining's binary_logloss: 0.198055\tvalid_1's binary_logloss: 0.246588\n",
      "[4110]\ttraining's binary_logloss: 0.197942\tvalid_1's binary_logloss: 0.246578\n",
      "[4120]\ttraining's binary_logloss: 0.197837\tvalid_1's binary_logloss: 0.246568\n",
      "[4130]\ttraining's binary_logloss: 0.197733\tvalid_1's binary_logloss: 0.246567\n",
      "[4140]\ttraining's binary_logloss: 0.197626\tvalid_1's binary_logloss: 0.246559\n",
      "[4150]\ttraining's binary_logloss: 0.197522\tvalid_1's binary_logloss: 0.246549\n",
      "[4160]\ttraining's binary_logloss: 0.197409\tvalid_1's binary_logloss: 0.246542\n",
      "[4170]\ttraining's binary_logloss: 0.197301\tvalid_1's binary_logloss: 0.246524\n",
      "[4180]\ttraining's binary_logloss: 0.197195\tvalid_1's binary_logloss: 0.246514\n",
      "[4190]\ttraining's binary_logloss: 0.19709\tvalid_1's binary_logloss: 0.246509\n",
      "[4200]\ttraining's binary_logloss: 0.196984\tvalid_1's binary_logloss: 0.246498\n",
      "[4210]\ttraining's binary_logloss: 0.196883\tvalid_1's binary_logloss: 0.246493\n",
      "[4220]\ttraining's binary_logloss: 0.196782\tvalid_1's binary_logloss: 0.246489\n",
      "[4230]\ttraining's binary_logloss: 0.196684\tvalid_1's binary_logloss: 0.246491\n",
      "[4240]\ttraining's binary_logloss: 0.196572\tvalid_1's binary_logloss: 0.246473\n",
      "[4250]\ttraining's binary_logloss: 0.196456\tvalid_1's binary_logloss: 0.24645\n",
      "[4260]\ttraining's binary_logloss: 0.196342\tvalid_1's binary_logloss: 0.246428\n",
      "[4270]\ttraining's binary_logloss: 0.196241\tvalid_1's binary_logloss: 0.246427\n",
      "[4280]\ttraining's binary_logloss: 0.19614\tvalid_1's binary_logloss: 0.246411\n",
      "[4290]\ttraining's binary_logloss: 0.196049\tvalid_1's binary_logloss: 0.246408\n",
      "[4300]\ttraining's binary_logloss: 0.195956\tvalid_1's binary_logloss: 0.246393\n",
      "[4310]\ttraining's binary_logloss: 0.19586\tvalid_1's binary_logloss: 0.246389\n",
      "[4320]\ttraining's binary_logloss: 0.195764\tvalid_1's binary_logloss: 0.246379\n",
      "[4330]\ttraining's binary_logloss: 0.195667\tvalid_1's binary_logloss: 0.24638\n",
      "[4340]\ttraining's binary_logloss: 0.195581\tvalid_1's binary_logloss: 0.246389\n",
      "[4350]\ttraining's binary_logloss: 0.19549\tvalid_1's binary_logloss: 0.246388\n",
      "[4360]\ttraining's binary_logloss: 0.195392\tvalid_1's binary_logloss: 0.246379\n",
      "[4370]\ttraining's binary_logloss: 0.195287\tvalid_1's binary_logloss: 0.246362\n",
      "[4380]\ttraining's binary_logloss: 0.195177\tvalid_1's binary_logloss: 0.24635\n",
      "[4390]\ttraining's binary_logloss: 0.19506\tvalid_1's binary_logloss: 0.246334\n",
      "[4400]\ttraining's binary_logloss: 0.194954\tvalid_1's binary_logloss: 0.246329\n",
      "[4410]\ttraining's binary_logloss: 0.194866\tvalid_1's binary_logloss: 0.246328\n",
      "[4420]\ttraining's binary_logloss: 0.194762\tvalid_1's binary_logloss: 0.246311\n",
      "[4430]\ttraining's binary_logloss: 0.194647\tvalid_1's binary_logloss: 0.246298\n",
      "[4440]\ttraining's binary_logloss: 0.194548\tvalid_1's binary_logloss: 0.246293\n",
      "[4450]\ttraining's binary_logloss: 0.194435\tvalid_1's binary_logloss: 0.246284\n",
      "[4460]\ttraining's binary_logloss: 0.194336\tvalid_1's binary_logloss: 0.246271\n",
      "[4470]\ttraining's binary_logloss: 0.194238\tvalid_1's binary_logloss: 0.246259\n",
      "[4480]\ttraining's binary_logloss: 0.194138\tvalid_1's binary_logloss: 0.246259\n",
      "[4490]\ttraining's binary_logloss: 0.194037\tvalid_1's binary_logloss: 0.246259\n",
      "[4500]\ttraining's binary_logloss: 0.19393\tvalid_1's binary_logloss: 0.246254\n",
      "[4510]\ttraining's binary_logloss: 0.193834\tvalid_1's binary_logloss: 0.246254\n",
      "[4520]\ttraining's binary_logloss: 0.193739\tvalid_1's binary_logloss: 0.246245\n",
      "[4530]\ttraining's binary_logloss: 0.193642\tvalid_1's binary_logloss: 0.24624\n",
      "[4540]\ttraining's binary_logloss: 0.193541\tvalid_1's binary_logloss: 0.246225\n",
      "[4550]\ttraining's binary_logloss: 0.193431\tvalid_1's binary_logloss: 0.246221\n",
      "[4560]\ttraining's binary_logloss: 0.193329\tvalid_1's binary_logloss: 0.246209\n",
      "[4570]\ttraining's binary_logloss: 0.193222\tvalid_1's binary_logloss: 0.246194\n",
      "[4580]\ttraining's binary_logloss: 0.193119\tvalid_1's binary_logloss: 0.246188\n",
      "[4590]\ttraining's binary_logloss: 0.193014\tvalid_1's binary_logloss: 0.246168\n",
      "[4600]\ttraining's binary_logloss: 0.192927\tvalid_1's binary_logloss: 0.246165\n",
      "[4610]\ttraining's binary_logloss: 0.19282\tvalid_1's binary_logloss: 0.246157\n",
      "[4620]\ttraining's binary_logloss: 0.192721\tvalid_1's binary_logloss: 0.246147\n",
      "[4630]\ttraining's binary_logloss: 0.192631\tvalid_1's binary_logloss: 0.246141\n",
      "[4640]\ttraining's binary_logloss: 0.192538\tvalid_1's binary_logloss: 0.246133\n",
      "[4650]\ttraining's binary_logloss: 0.192446\tvalid_1's binary_logloss: 0.246137\n",
      "[4660]\ttraining's binary_logloss: 0.192345\tvalid_1's binary_logloss: 0.246129\n",
      "[4670]\ttraining's binary_logloss: 0.192246\tvalid_1's binary_logloss: 0.246126\n",
      "[4680]\ttraining's binary_logloss: 0.192144\tvalid_1's binary_logloss: 0.246121\n",
      "[4690]\ttraining's binary_logloss: 0.192047\tvalid_1's binary_logloss: 0.246116\n",
      "[4700]\ttraining's binary_logloss: 0.191952\tvalid_1's binary_logloss: 0.246107\n",
      "[4710]\ttraining's binary_logloss: 0.191846\tvalid_1's binary_logloss: 0.246101\n",
      "[4720]\ttraining's binary_logloss: 0.191738\tvalid_1's binary_logloss: 0.246089\n",
      "[4730]\ttraining's binary_logloss: 0.191632\tvalid_1's binary_logloss: 0.246082\n",
      "[4740]\ttraining's binary_logloss: 0.191536\tvalid_1's binary_logloss: 0.246079\n",
      "[4750]\ttraining's binary_logloss: 0.191426\tvalid_1's binary_logloss: 0.24606\n",
      "[4760]\ttraining's binary_logloss: 0.191334\tvalid_1's binary_logloss: 0.246061\n",
      "[4770]\ttraining's binary_logloss: 0.191227\tvalid_1's binary_logloss: 0.246065\n",
      "[4780]\ttraining's binary_logloss: 0.191131\tvalid_1's binary_logloss: 0.246057\n",
      "[4790]\ttraining's binary_logloss: 0.191036\tvalid_1's binary_logloss: 0.246046\n",
      "[4800]\ttraining's binary_logloss: 0.190934\tvalid_1's binary_logloss: 0.246043\n",
      "[4810]\ttraining's binary_logloss: 0.190846\tvalid_1's binary_logloss: 0.246038\n",
      "[4820]\ttraining's binary_logloss: 0.19074\tvalid_1's binary_logloss: 0.246023\n",
      "[4830]\ttraining's binary_logloss: 0.190637\tvalid_1's binary_logloss: 0.246012\n",
      "[4840]\ttraining's binary_logloss: 0.19054\tvalid_1's binary_logloss: 0.246009\n",
      "[4850]\ttraining's binary_logloss: 0.19045\tvalid_1's binary_logloss: 0.24601\n",
      "[4860]\ttraining's binary_logloss: 0.190355\tvalid_1's binary_logloss: 0.246009\n",
      "[4870]\ttraining's binary_logloss: 0.190257\tvalid_1's binary_logloss: 0.245992\n",
      "[4880]\ttraining's binary_logloss: 0.190167\tvalid_1's binary_logloss: 0.245987\n",
      "[4890]\ttraining's binary_logloss: 0.190071\tvalid_1's binary_logloss: 0.245985\n",
      "[4900]\ttraining's binary_logloss: 0.189964\tvalid_1's binary_logloss: 0.245965\n",
      "[4910]\ttraining's binary_logloss: 0.189871\tvalid_1's binary_logloss: 0.245959\n",
      "[4920]\ttraining's binary_logloss: 0.18979\tvalid_1's binary_logloss: 0.245953\n",
      "[4930]\ttraining's binary_logloss: 0.189691\tvalid_1's binary_logloss: 0.245951\n",
      "[4940]\ttraining's binary_logloss: 0.18959\tvalid_1's binary_logloss: 0.245949\n",
      "[4950]\ttraining's binary_logloss: 0.189491\tvalid_1's binary_logloss: 0.245943\n",
      "[4960]\ttraining's binary_logloss: 0.189396\tvalid_1's binary_logloss: 0.245937\n",
      "[4970]\ttraining's binary_logloss: 0.189296\tvalid_1's binary_logloss: 0.245924\n",
      "[4980]\ttraining's binary_logloss: 0.189191\tvalid_1's binary_logloss: 0.245907\n",
      "[4990]\ttraining's binary_logloss: 0.18909\tvalid_1's binary_logloss: 0.2459\n",
      "[5000]\ttraining's binary_logloss: 0.188976\tvalid_1's binary_logloss: 0.245875\n",
      "[5010]\ttraining's binary_logloss: 0.188854\tvalid_1's binary_logloss: 0.245843\n",
      "[5020]\ttraining's binary_logloss: 0.188762\tvalid_1's binary_logloss: 0.245841\n",
      "[5030]\ttraining's binary_logloss: 0.188664\tvalid_1's binary_logloss: 0.245835\n",
      "[5040]\ttraining's binary_logloss: 0.188573\tvalid_1's binary_logloss: 0.245827\n",
      "[5050]\ttraining's binary_logloss: 0.188481\tvalid_1's binary_logloss: 0.245822\n",
      "[5060]\ttraining's binary_logloss: 0.188384\tvalid_1's binary_logloss: 0.245813\n",
      "[5070]\ttraining's binary_logloss: 0.188283\tvalid_1's binary_logloss: 0.245808\n",
      "[5080]\ttraining's binary_logloss: 0.188195\tvalid_1's binary_logloss: 0.245806\n",
      "[5090]\ttraining's binary_logloss: 0.188095\tvalid_1's binary_logloss: 0.245799\n",
      "[5100]\ttraining's binary_logloss: 0.187995\tvalid_1's binary_logloss: 0.245776\n",
      "[5110]\ttraining's binary_logloss: 0.187879\tvalid_1's binary_logloss: 0.245757\n",
      "[5120]\ttraining's binary_logloss: 0.187789\tvalid_1's binary_logloss: 0.24576\n",
      "[5130]\ttraining's binary_logloss: 0.187694\tvalid_1's binary_logloss: 0.245748\n",
      "[5140]\ttraining's binary_logloss: 0.187606\tvalid_1's binary_logloss: 0.245741\n",
      "[5150]\ttraining's binary_logloss: 0.187497\tvalid_1's binary_logloss: 0.245737\n",
      "[5160]\ttraining's binary_logloss: 0.187409\tvalid_1's binary_logloss: 0.245733\n",
      "[5170]\ttraining's binary_logloss: 0.187306\tvalid_1's binary_logloss: 0.245717\n",
      "[5180]\ttraining's binary_logloss: 0.187195\tvalid_1's binary_logloss: 0.245699\n",
      "[5190]\ttraining's binary_logloss: 0.187101\tvalid_1's binary_logloss: 0.24569\n",
      "[5200]\ttraining's binary_logloss: 0.187011\tvalid_1's binary_logloss: 0.245687\n",
      "[5210]\ttraining's binary_logloss: 0.186924\tvalid_1's binary_logloss: 0.245675\n",
      "[5220]\ttraining's binary_logloss: 0.186826\tvalid_1's binary_logloss: 0.245678\n",
      "[5230]\ttraining's binary_logloss: 0.186722\tvalid_1's binary_logloss: 0.245671\n",
      "[5240]\ttraining's binary_logloss: 0.186621\tvalid_1's binary_logloss: 0.245652\n",
      "[5250]\ttraining's binary_logloss: 0.186522\tvalid_1's binary_logloss: 0.245634\n",
      "[5260]\ttraining's binary_logloss: 0.186417\tvalid_1's binary_logloss: 0.245621\n",
      "[5270]\ttraining's binary_logloss: 0.186319\tvalid_1's binary_logloss: 0.245604\n",
      "[5280]\ttraining's binary_logloss: 0.186219\tvalid_1's binary_logloss: 0.245601\n",
      "[5290]\ttraining's binary_logloss: 0.18612\tvalid_1's binary_logloss: 0.245599\n",
      "[5300]\ttraining's binary_logloss: 0.186028\tvalid_1's binary_logloss: 0.245596\n",
      "[5310]\ttraining's binary_logloss: 0.185934\tvalid_1's binary_logloss: 0.245589\n",
      "[5320]\ttraining's binary_logloss: 0.185833\tvalid_1's binary_logloss: 0.245577\n",
      "[5330]\ttraining's binary_logloss: 0.185742\tvalid_1's binary_logloss: 0.245572\n",
      "[5340]\ttraining's binary_logloss: 0.185658\tvalid_1's binary_logloss: 0.245577\n",
      "[5350]\ttraining's binary_logloss: 0.185577\tvalid_1's binary_logloss: 0.245569\n",
      "[5360]\ttraining's binary_logloss: 0.185494\tvalid_1's binary_logloss: 0.245561\n",
      "[5370]\ttraining's binary_logloss: 0.185405\tvalid_1's binary_logloss: 0.245563\n",
      "[5380]\ttraining's binary_logloss: 0.185324\tvalid_1's binary_logloss: 0.24556\n",
      "[5390]\ttraining's binary_logloss: 0.185225\tvalid_1's binary_logloss: 0.245547\n",
      "[5400]\ttraining's binary_logloss: 0.18512\tvalid_1's binary_logloss: 0.245529\n",
      "[5410]\ttraining's binary_logloss: 0.185031\tvalid_1's binary_logloss: 0.245521\n",
      "[5420]\ttraining's binary_logloss: 0.184931\tvalid_1's binary_logloss: 0.245509\n",
      "[5430]\ttraining's binary_logloss: 0.184829\tvalid_1's binary_logloss: 0.245502\n",
      "[5440]\ttraining's binary_logloss: 0.184746\tvalid_1's binary_logloss: 0.245504\n",
      "[5450]\ttraining's binary_logloss: 0.184657\tvalid_1's binary_logloss: 0.245502\n",
      "[5460]\ttraining's binary_logloss: 0.184565\tvalid_1's binary_logloss: 0.245499\n",
      "[5470]\ttraining's binary_logloss: 0.184481\tvalid_1's binary_logloss: 0.245506\n",
      "[5480]\ttraining's binary_logloss: 0.184386\tvalid_1's binary_logloss: 0.245506\n",
      "[5490]\ttraining's binary_logloss: 0.184306\tvalid_1's binary_logloss: 0.245506\n",
      "[5500]\ttraining's binary_logloss: 0.184208\tvalid_1's binary_logloss: 0.245497\n",
      "[5510]\ttraining's binary_logloss: 0.184111\tvalid_1's binary_logloss: 0.245498\n",
      "[5520]\ttraining's binary_logloss: 0.184017\tvalid_1's binary_logloss: 0.245497\n",
      "[5530]\ttraining's binary_logloss: 0.183921\tvalid_1's binary_logloss: 0.245482\n",
      "[5540]\ttraining's binary_logloss: 0.183822\tvalid_1's binary_logloss: 0.24547\n",
      "[5550]\ttraining's binary_logloss: 0.183729\tvalid_1's binary_logloss: 0.245473\n",
      "[5560]\ttraining's binary_logloss: 0.183652\tvalid_1's binary_logloss: 0.245469\n",
      "[5570]\ttraining's binary_logloss: 0.183554\tvalid_1's binary_logloss: 0.245469\n",
      "[5580]\ttraining's binary_logloss: 0.183453\tvalid_1's binary_logloss: 0.24547\n",
      "[5590]\ttraining's binary_logloss: 0.183359\tvalid_1's binary_logloss: 0.245467\n",
      "[5600]\ttraining's binary_logloss: 0.183257\tvalid_1's binary_logloss: 0.245458\n",
      "[5610]\ttraining's binary_logloss: 0.183169\tvalid_1's binary_logloss: 0.245445\n",
      "[5620]\ttraining's binary_logloss: 0.183073\tvalid_1's binary_logloss: 0.245431\n",
      "[5630]\ttraining's binary_logloss: 0.182993\tvalid_1's binary_logloss: 0.245429\n",
      "[5640]\ttraining's binary_logloss: 0.182899\tvalid_1's binary_logloss: 0.245421\n",
      "[5650]\ttraining's binary_logloss: 0.182812\tvalid_1's binary_logloss: 0.245422\n",
      "[5660]\ttraining's binary_logloss: 0.18271\tvalid_1's binary_logloss: 0.245407\n",
      "[5670]\ttraining's binary_logloss: 0.182632\tvalid_1's binary_logloss: 0.245407\n",
      "[5680]\ttraining's binary_logloss: 0.182528\tvalid_1's binary_logloss: 0.245406\n",
      "[5690]\ttraining's binary_logloss: 0.182441\tvalid_1's binary_logloss: 0.245402\n",
      "[5700]\ttraining's binary_logloss: 0.182334\tvalid_1's binary_logloss: 0.245392\n",
      "[5710]\ttraining's binary_logloss: 0.182251\tvalid_1's binary_logloss: 0.245391\n",
      "[5720]\ttraining's binary_logloss: 0.182175\tvalid_1's binary_logloss: 0.245399\n",
      "[5730]\ttraining's binary_logloss: 0.182085\tvalid_1's binary_logloss: 0.245393\n",
      "[5740]\ttraining's binary_logloss: 0.182002\tvalid_1's binary_logloss: 0.245396\n",
      "[5750]\ttraining's binary_logloss: 0.18191\tvalid_1's binary_logloss: 0.245395\n",
      "[5760]\ttraining's binary_logloss: 0.181813\tvalid_1's binary_logloss: 0.245393\n",
      "[5770]\ttraining's binary_logloss: 0.18174\tvalid_1's binary_logloss: 0.24539\n",
      "[5780]\ttraining's binary_logloss: 0.18166\tvalid_1's binary_logloss: 0.245385\n",
      "[5790]\ttraining's binary_logloss: 0.181572\tvalid_1's binary_logloss: 0.245375\n",
      "[5800]\ttraining's binary_logloss: 0.181482\tvalid_1's binary_logloss: 0.245368\n",
      "[5810]\ttraining's binary_logloss: 0.181389\tvalid_1's binary_logloss: 0.245362\n",
      "[5820]\ttraining's binary_logloss: 0.181302\tvalid_1's binary_logloss: 0.245353\n",
      "[5830]\ttraining's binary_logloss: 0.181228\tvalid_1's binary_logloss: 0.245349\n",
      "[5840]\ttraining's binary_logloss: 0.181142\tvalid_1's binary_logloss: 0.245341\n",
      "[5850]\ttraining's binary_logloss: 0.181042\tvalid_1's binary_logloss: 0.245335\n",
      "[5860]\ttraining's binary_logloss: 0.180953\tvalid_1's binary_logloss: 0.245337\n",
      "[5870]\ttraining's binary_logloss: 0.180845\tvalid_1's binary_logloss: 0.245329\n",
      "[5880]\ttraining's binary_logloss: 0.180749\tvalid_1's binary_logloss: 0.245326\n",
      "[5890]\ttraining's binary_logloss: 0.180659\tvalid_1's binary_logloss: 0.245313\n",
      "[5900]\ttraining's binary_logloss: 0.180557\tvalid_1's binary_logloss: 0.245296\n",
      "[5910]\ttraining's binary_logloss: 0.180472\tvalid_1's binary_logloss: 0.24529\n",
      "[5920]\ttraining's binary_logloss: 0.180385\tvalid_1's binary_logloss: 0.245285\n",
      "[5930]\ttraining's binary_logloss: 0.180289\tvalid_1's binary_logloss: 0.245283\n",
      "[5940]\ttraining's binary_logloss: 0.180204\tvalid_1's binary_logloss: 0.245278\n",
      "[5950]\ttraining's binary_logloss: 0.180102\tvalid_1's binary_logloss: 0.245268\n",
      "[5960]\ttraining's binary_logloss: 0.180028\tvalid_1's binary_logloss: 0.245269\n",
      "[5970]\ttraining's binary_logloss: 0.179945\tvalid_1's binary_logloss: 0.245271\n",
      "[5980]\ttraining's binary_logloss: 0.179862\tvalid_1's binary_logloss: 0.245265\n",
      "[5990]\ttraining's binary_logloss: 0.179786\tvalid_1's binary_logloss: 0.245268\n",
      "[6000]\ttraining's binary_logloss: 0.179696\tvalid_1's binary_logloss: 0.245259\n",
      "[6010]\ttraining's binary_logloss: 0.179608\tvalid_1's binary_logloss: 0.245264\n",
      "[6020]\ttraining's binary_logloss: 0.179533\tvalid_1's binary_logloss: 0.245262\n",
      "[6030]\ttraining's binary_logloss: 0.17945\tvalid_1's binary_logloss: 0.245258\n",
      "[6040]\ttraining's binary_logloss: 0.179366\tvalid_1's binary_logloss: 0.245253\n",
      "[6050]\ttraining's binary_logloss: 0.179276\tvalid_1's binary_logloss: 0.245239\n",
      "[6060]\ttraining's binary_logloss: 0.179198\tvalid_1's binary_logloss: 0.245237\n",
      "[6070]\ttraining's binary_logloss: 0.179118\tvalid_1's binary_logloss: 0.245231\n",
      "[6080]\ttraining's binary_logloss: 0.179029\tvalid_1's binary_logloss: 0.245222\n",
      "[6090]\ttraining's binary_logloss: 0.178943\tvalid_1's binary_logloss: 0.245217\n",
      "[6100]\ttraining's binary_logloss: 0.178854\tvalid_1's binary_logloss: 0.245213\n",
      "[6110]\ttraining's binary_logloss: 0.178774\tvalid_1's binary_logloss: 0.245213\n",
      "[6120]\ttraining's binary_logloss: 0.178697\tvalid_1's binary_logloss: 0.245204\n",
      "[6130]\ttraining's binary_logloss: 0.178618\tvalid_1's binary_logloss: 0.245205\n",
      "[6140]\ttraining's binary_logloss: 0.178535\tvalid_1's binary_logloss: 0.245196\n",
      "[6150]\ttraining's binary_logloss: 0.178447\tvalid_1's binary_logloss: 0.24519\n",
      "[6160]\ttraining's binary_logloss: 0.178372\tvalid_1's binary_logloss: 0.245193\n",
      "[6170]\ttraining's binary_logloss: 0.178293\tvalid_1's binary_logloss: 0.245193\n",
      "[6180]\ttraining's binary_logloss: 0.17821\tvalid_1's binary_logloss: 0.245188\n",
      "[6190]\ttraining's binary_logloss: 0.178118\tvalid_1's binary_logloss: 0.245179\n",
      "[6200]\ttraining's binary_logloss: 0.178025\tvalid_1's binary_logloss: 0.245178\n",
      "[6210]\ttraining's binary_logloss: 0.177929\tvalid_1's binary_logloss: 0.245175\n",
      "[6220]\ttraining's binary_logloss: 0.177846\tvalid_1's binary_logloss: 0.245171\n",
      "[6230]\ttraining's binary_logloss: 0.177755\tvalid_1's binary_logloss: 0.245163\n",
      "[6240]\ttraining's binary_logloss: 0.177675\tvalid_1's binary_logloss: 0.245159\n",
      "[6250]\ttraining's binary_logloss: 0.177589\tvalid_1's binary_logloss: 0.245152\n",
      "[6260]\ttraining's binary_logloss: 0.177506\tvalid_1's binary_logloss: 0.245138\n",
      "[6270]\ttraining's binary_logloss: 0.177415\tvalid_1's binary_logloss: 0.24513\n",
      "[6280]\ttraining's binary_logloss: 0.177331\tvalid_1's binary_logloss: 0.245128\n",
      "[6290]\ttraining's binary_logloss: 0.17725\tvalid_1's binary_logloss: 0.245123\n",
      "[6300]\ttraining's binary_logloss: 0.177175\tvalid_1's binary_logloss: 0.245117\n",
      "[6310]\ttraining's binary_logloss: 0.177086\tvalid_1's binary_logloss: 0.245113\n",
      "[6320]\ttraining's binary_logloss: 0.177007\tvalid_1's binary_logloss: 0.245112\n",
      "[6330]\ttraining's binary_logloss: 0.176929\tvalid_1's binary_logloss: 0.245115\n",
      "[6340]\ttraining's binary_logloss: 0.176846\tvalid_1's binary_logloss: 0.245111\n",
      "[6350]\ttraining's binary_logloss: 0.176753\tvalid_1's binary_logloss: 0.245102\n",
      "[6360]\ttraining's binary_logloss: 0.176671\tvalid_1's binary_logloss: 0.245095\n",
      "[6370]\ttraining's binary_logloss: 0.176592\tvalid_1's binary_logloss: 0.2451\n",
      "[6380]\ttraining's binary_logloss: 0.176516\tvalid_1's binary_logloss: 0.245097\n",
      "[6390]\ttraining's binary_logloss: 0.176432\tvalid_1's binary_logloss: 0.24509\n",
      "[6400]\ttraining's binary_logloss: 0.176356\tvalid_1's binary_logloss: 0.245091\n",
      "[6410]\ttraining's binary_logloss: 0.176276\tvalid_1's binary_logloss: 0.24509\n",
      "[6420]\ttraining's binary_logloss: 0.17619\tvalid_1's binary_logloss: 0.245078\n",
      "[6430]\ttraining's binary_logloss: 0.176102\tvalid_1's binary_logloss: 0.245077\n",
      "[6440]\ttraining's binary_logloss: 0.176019\tvalid_1's binary_logloss: 0.245076\n",
      "[6450]\ttraining's binary_logloss: 0.175932\tvalid_1's binary_logloss: 0.245065\n",
      "[6460]\ttraining's binary_logloss: 0.175852\tvalid_1's binary_logloss: 0.245068\n",
      "[6470]\ttraining's binary_logloss: 0.175771\tvalid_1's binary_logloss: 0.245071\n",
      "[6480]\ttraining's binary_logloss: 0.175691\tvalid_1's binary_logloss: 0.245067\n",
      "[6490]\ttraining's binary_logloss: 0.175601\tvalid_1's binary_logloss: 0.245064\n",
      "[6500]\ttraining's binary_logloss: 0.175516\tvalid_1's binary_logloss: 0.245058\n",
      "[6510]\ttraining's binary_logloss: 0.175426\tvalid_1's binary_logloss: 0.245049\n",
      "[6520]\ttraining's binary_logloss: 0.175335\tvalid_1's binary_logloss: 0.245036\n",
      "[6530]\ttraining's binary_logloss: 0.175252\tvalid_1's binary_logloss: 0.245038\n",
      "[6540]\ttraining's binary_logloss: 0.175158\tvalid_1's binary_logloss: 0.245024\n",
      "[6550]\ttraining's binary_logloss: 0.175077\tvalid_1's binary_logloss: 0.245022\n",
      "[6560]\ttraining's binary_logloss: 0.17499\tvalid_1's binary_logloss: 0.245027\n",
      "[6570]\ttraining's binary_logloss: 0.174906\tvalid_1's binary_logloss: 0.245021\n",
      "[6580]\ttraining's binary_logloss: 0.17483\tvalid_1's binary_logloss: 0.24501\n",
      "[6590]\ttraining's binary_logloss: 0.174745\tvalid_1's binary_logloss: 0.245006\n",
      "[6600]\ttraining's binary_logloss: 0.174674\tvalid_1's binary_logloss: 0.245007\n",
      "[6610]\ttraining's binary_logloss: 0.174589\tvalid_1's binary_logloss: 0.244997\n",
      "[6620]\ttraining's binary_logloss: 0.174498\tvalid_1's binary_logloss: 0.244992\n",
      "[6630]\ttraining's binary_logloss: 0.174415\tvalid_1's binary_logloss: 0.244994\n",
      "[6640]\ttraining's binary_logloss: 0.174316\tvalid_1's binary_logloss: 0.24499\n",
      "[6650]\ttraining's binary_logloss: 0.174238\tvalid_1's binary_logloss: 0.244988\n",
      "[6660]\ttraining's binary_logloss: 0.174145\tvalid_1's binary_logloss: 0.244976\n",
      "[6670]\ttraining's binary_logloss: 0.174071\tvalid_1's binary_logloss: 0.244966\n",
      "[6680]\ttraining's binary_logloss: 0.17399\tvalid_1's binary_logloss: 0.244959\n",
      "[6690]\ttraining's binary_logloss: 0.173902\tvalid_1's binary_logloss: 0.244953\n",
      "[6700]\ttraining's binary_logloss: 0.173816\tvalid_1's binary_logloss: 0.244945\n",
      "[6710]\ttraining's binary_logloss: 0.173739\tvalid_1's binary_logloss: 0.244946\n",
      "[6720]\ttraining's binary_logloss: 0.173645\tvalid_1's binary_logloss: 0.244937\n",
      "[6730]\ttraining's binary_logloss: 0.173565\tvalid_1's binary_logloss: 0.24494\n",
      "[6740]\ttraining's binary_logloss: 0.173484\tvalid_1's binary_logloss: 0.24493\n",
      "[6750]\ttraining's binary_logloss: 0.173393\tvalid_1's binary_logloss: 0.244929\n",
      "[6760]\ttraining's binary_logloss: 0.173305\tvalid_1's binary_logloss: 0.244917\n",
      "[6770]\ttraining's binary_logloss: 0.173216\tvalid_1's binary_logloss: 0.244913\n",
      "[6780]\ttraining's binary_logloss: 0.173136\tvalid_1's binary_logloss: 0.244906\n",
      "[6790]\ttraining's binary_logloss: 0.173048\tvalid_1's binary_logloss: 0.244907\n",
      "[6800]\ttraining's binary_logloss: 0.172962\tvalid_1's binary_logloss: 0.244897\n",
      "[6810]\ttraining's binary_logloss: 0.172886\tvalid_1's binary_logloss: 0.244899\n",
      "[6820]\ttraining's binary_logloss: 0.172796\tvalid_1's binary_logloss: 0.244893\n",
      "[6830]\ttraining's binary_logloss: 0.172715\tvalid_1's binary_logloss: 0.244886\n",
      "[6840]\ttraining's binary_logloss: 0.172643\tvalid_1's binary_logloss: 0.244885\n",
      "[6850]\ttraining's binary_logloss: 0.17256\tvalid_1's binary_logloss: 0.244885\n",
      "[6860]\ttraining's binary_logloss: 0.172476\tvalid_1's binary_logloss: 0.244883\n",
      "[6870]\ttraining's binary_logloss: 0.172395\tvalid_1's binary_logloss: 0.24488\n",
      "[6880]\ttraining's binary_logloss: 0.172315\tvalid_1's binary_logloss: 0.244881\n",
      "[6890]\ttraining's binary_logloss: 0.172239\tvalid_1's binary_logloss: 0.244878\n",
      "[6900]\ttraining's binary_logloss: 0.172159\tvalid_1's binary_logloss: 0.244874\n",
      "[6910]\ttraining's binary_logloss: 0.172078\tvalid_1's binary_logloss: 0.244874\n",
      "[6920]\ttraining's binary_logloss: 0.172\tvalid_1's binary_logloss: 0.24487\n",
      "[6930]\ttraining's binary_logloss: 0.171918\tvalid_1's binary_logloss: 0.244876\n",
      "[6940]\ttraining's binary_logloss: 0.171839\tvalid_1's binary_logloss: 0.244873\n",
      "[6950]\ttraining's binary_logloss: 0.171754\tvalid_1's binary_logloss: 0.244872\n",
      "[6960]\ttraining's binary_logloss: 0.171664\tvalid_1's binary_logloss: 0.244871\n",
      "[6970]\ttraining's binary_logloss: 0.171576\tvalid_1's binary_logloss: 0.244872\n",
      "[6980]\ttraining's binary_logloss: 0.171486\tvalid_1's binary_logloss: 0.244864\n",
      "[6990]\ttraining's binary_logloss: 0.171397\tvalid_1's binary_logloss: 0.244863\n",
      "[7000]\ttraining's binary_logloss: 0.17132\tvalid_1's binary_logloss: 0.244869\n",
      "[7010]\ttraining's binary_logloss: 0.171243\tvalid_1's binary_logloss: 0.24487\n",
      "[7020]\ttraining's binary_logloss: 0.171163\tvalid_1's binary_logloss: 0.244861\n",
      "[7030]\ttraining's binary_logloss: 0.171082\tvalid_1's binary_logloss: 0.244861\n",
      "[7040]\ttraining's binary_logloss: 0.170997\tvalid_1's binary_logloss: 0.244857\n",
      "[7050]\ttraining's binary_logloss: 0.170899\tvalid_1's binary_logloss: 0.244846\n",
      "[7060]\ttraining's binary_logloss: 0.170817\tvalid_1's binary_logloss: 0.244839\n",
      "[7070]\ttraining's binary_logloss: 0.170723\tvalid_1's binary_logloss: 0.244826\n",
      "[7080]\ttraining's binary_logloss: 0.170638\tvalid_1's binary_logloss: 0.244817\n",
      "[7090]\ttraining's binary_logloss: 0.170552\tvalid_1's binary_logloss: 0.244818\n",
      "[7100]\ttraining's binary_logloss: 0.17046\tvalid_1's binary_logloss: 0.244812\n",
      "[7110]\ttraining's binary_logloss: 0.170368\tvalid_1's binary_logloss: 0.244806\n",
      "[7120]\ttraining's binary_logloss: 0.17028\tvalid_1's binary_logloss: 0.244808\n",
      "[7130]\ttraining's binary_logloss: 0.1702\tvalid_1's binary_logloss: 0.24481\n",
      "[7140]\ttraining's binary_logloss: 0.1701\tvalid_1's binary_logloss: 0.244795\n",
      "[7150]\ttraining's binary_logloss: 0.170015\tvalid_1's binary_logloss: 0.24479\n",
      "[7160]\ttraining's binary_logloss: 0.169935\tvalid_1's binary_logloss: 0.244794\n",
      "[7170]\ttraining's binary_logloss: 0.16986\tvalid_1's binary_logloss: 0.244792\n",
      "[7180]\ttraining's binary_logloss: 0.169772\tvalid_1's binary_logloss: 0.244781\n",
      "[7190]\ttraining's binary_logloss: 0.169689\tvalid_1's binary_logloss: 0.244784\n",
      "[7200]\ttraining's binary_logloss: 0.169601\tvalid_1's binary_logloss: 0.244772\n",
      "[7210]\ttraining's binary_logloss: 0.16953\tvalid_1's binary_logloss: 0.244772\n",
      "[7220]\ttraining's binary_logloss: 0.169455\tvalid_1's binary_logloss: 0.244773\n",
      "[7230]\ttraining's binary_logloss: 0.169367\tvalid_1's binary_logloss: 0.244773\n",
      "[7240]\ttraining's binary_logloss: 0.16929\tvalid_1's binary_logloss: 0.244777\n",
      "[7250]\ttraining's binary_logloss: 0.169196\tvalid_1's binary_logloss: 0.244775\n",
      "[7260]\ttraining's binary_logloss: 0.169104\tvalid_1's binary_logloss: 0.244765\n",
      "[7270]\ttraining's binary_logloss: 0.16903\tvalid_1's binary_logloss: 0.244765\n",
      "[7280]\ttraining's binary_logloss: 0.168942\tvalid_1's binary_logloss: 0.244761\n",
      "[7290]\ttraining's binary_logloss: 0.168863\tvalid_1's binary_logloss: 0.244755\n",
      "[7300]\ttraining's binary_logloss: 0.168788\tvalid_1's binary_logloss: 0.244754\n",
      "[7310]\ttraining's binary_logloss: 0.168716\tvalid_1's binary_logloss: 0.244763\n",
      "[7320]\ttraining's binary_logloss: 0.168637\tvalid_1's binary_logloss: 0.24476\n",
      "[7330]\ttraining's binary_logloss: 0.16856\tvalid_1's binary_logloss: 0.244768\n",
      "[7340]\ttraining's binary_logloss: 0.168482\tvalid_1's binary_logloss: 0.244767\n",
      "[7350]\ttraining's binary_logloss: 0.168411\tvalid_1's binary_logloss: 0.244759\n",
      "[7360]\ttraining's binary_logloss: 0.168334\tvalid_1's binary_logloss: 0.244751\n",
      "[7370]\ttraining's binary_logloss: 0.168252\tvalid_1's binary_logloss: 0.244745\n",
      "[7380]\ttraining's binary_logloss: 0.168185\tvalid_1's binary_logloss: 0.244742\n",
      "[7390]\ttraining's binary_logloss: 0.168105\tvalid_1's binary_logloss: 0.244744\n",
      "[7400]\ttraining's binary_logloss: 0.168032\tvalid_1's binary_logloss: 0.244743\n",
      "[7410]\ttraining's binary_logloss: 0.167948\tvalid_1's binary_logloss: 0.244744\n",
      "[7420]\ttraining's binary_logloss: 0.167868\tvalid_1's binary_logloss: 0.244732\n",
      "[7430]\ttraining's binary_logloss: 0.167777\tvalid_1's binary_logloss: 0.244728\n",
      "[7440]\ttraining's binary_logloss: 0.167696\tvalid_1's binary_logloss: 0.24472\n",
      "[7450]\ttraining's binary_logloss: 0.167611\tvalid_1's binary_logloss: 0.244719\n",
      "[7460]\ttraining's binary_logloss: 0.167536\tvalid_1's binary_logloss: 0.244727\n",
      "[7470]\ttraining's binary_logloss: 0.167457\tvalid_1's binary_logloss: 0.244721\n",
      "[7480]\ttraining's binary_logloss: 0.167368\tvalid_1's binary_logloss: 0.24472\n",
      "[7490]\ttraining's binary_logloss: 0.16729\tvalid_1's binary_logloss: 0.244704\n",
      "[7500]\ttraining's binary_logloss: 0.167221\tvalid_1's binary_logloss: 0.2447\n",
      "[7510]\ttraining's binary_logloss: 0.167135\tvalid_1's binary_logloss: 0.244692\n",
      "[7520]\ttraining's binary_logloss: 0.167044\tvalid_1's binary_logloss: 0.244687\n",
      "[7530]\ttraining's binary_logloss: 0.166976\tvalid_1's binary_logloss: 0.244687\n",
      "[7540]\ttraining's binary_logloss: 0.166895\tvalid_1's binary_logloss: 0.244682\n",
      "[7550]\ttraining's binary_logloss: 0.166809\tvalid_1's binary_logloss: 0.244679\n",
      "[7560]\ttraining's binary_logloss: 0.166737\tvalid_1's binary_logloss: 0.244678\n",
      "[7570]\ttraining's binary_logloss: 0.166653\tvalid_1's binary_logloss: 0.244681\n",
      "[7580]\ttraining's binary_logloss: 0.166584\tvalid_1's binary_logloss: 0.244685\n",
      "[7590]\ttraining's binary_logloss: 0.16651\tvalid_1's binary_logloss: 0.244681\n",
      "[7600]\ttraining's binary_logloss: 0.166434\tvalid_1's binary_logloss: 0.24468\n",
      "[7610]\ttraining's binary_logloss: 0.166351\tvalid_1's binary_logloss: 0.244674\n",
      "[7620]\ttraining's binary_logloss: 0.166269\tvalid_1's binary_logloss: 0.244667\n",
      "[7630]\ttraining's binary_logloss: 0.166189\tvalid_1's binary_logloss: 0.244663\n",
      "[7640]\ttraining's binary_logloss: 0.166109\tvalid_1's binary_logloss: 0.244655\n",
      "[7650]\ttraining's binary_logloss: 0.166024\tvalid_1's binary_logloss: 0.244643\n",
      "[7660]\ttraining's binary_logloss: 0.165947\tvalid_1's binary_logloss: 0.244641\n",
      "[7670]\ttraining's binary_logloss: 0.165869\tvalid_1's binary_logloss: 0.244642\n",
      "[7680]\ttraining's binary_logloss: 0.165799\tvalid_1's binary_logloss: 0.244639\n",
      "[7690]\ttraining's binary_logloss: 0.165727\tvalid_1's binary_logloss: 0.244638\n",
      "[7700]\ttraining's binary_logloss: 0.165654\tvalid_1's binary_logloss: 0.244638\n",
      "[7710]\ttraining's binary_logloss: 0.165577\tvalid_1's binary_logloss: 0.244636\n",
      "[7720]\ttraining's binary_logloss: 0.165496\tvalid_1's binary_logloss: 0.244638\n",
      "[7730]\ttraining's binary_logloss: 0.165412\tvalid_1's binary_logloss: 0.244632\n",
      "[7740]\ttraining's binary_logloss: 0.165333\tvalid_1's binary_logloss: 0.244631\n",
      "[7750]\ttraining's binary_logloss: 0.16525\tvalid_1's binary_logloss: 0.244629\n",
      "[7760]\ttraining's binary_logloss: 0.165171\tvalid_1's binary_logloss: 0.244627\n",
      "[7770]\ttraining's binary_logloss: 0.165099\tvalid_1's binary_logloss: 0.244624\n",
      "[7780]\ttraining's binary_logloss: 0.165022\tvalid_1's binary_logloss: 0.244624\n",
      "[7790]\ttraining's binary_logloss: 0.164956\tvalid_1's binary_logloss: 0.244623\n",
      "[7800]\ttraining's binary_logloss: 0.164875\tvalid_1's binary_logloss: 0.244625\n",
      "[7810]\ttraining's binary_logloss: 0.164795\tvalid_1's binary_logloss: 0.244614\n",
      "[7820]\ttraining's binary_logloss: 0.164702\tvalid_1's binary_logloss: 0.244601\n",
      "[7830]\ttraining's binary_logloss: 0.164623\tvalid_1's binary_logloss: 0.244598\n",
      "[7840]\ttraining's binary_logloss: 0.16454\tvalid_1's binary_logloss: 0.24459\n",
      "[7850]\ttraining's binary_logloss: 0.164449\tvalid_1's binary_logloss: 0.244588\n",
      "[7860]\ttraining's binary_logloss: 0.164367\tvalid_1's binary_logloss: 0.244577\n",
      "[7870]\ttraining's binary_logloss: 0.164284\tvalid_1's binary_logloss: 0.244563\n",
      "[7880]\ttraining's binary_logloss: 0.164207\tvalid_1's binary_logloss: 0.244553\n",
      "[7890]\ttraining's binary_logloss: 0.164123\tvalid_1's binary_logloss: 0.244562\n",
      "[7900]\ttraining's binary_logloss: 0.164043\tvalid_1's binary_logloss: 0.244552\n",
      "[7910]\ttraining's binary_logloss: 0.163959\tvalid_1's binary_logloss: 0.244542\n",
      "[7920]\ttraining's binary_logloss: 0.163891\tvalid_1's binary_logloss: 0.24454\n",
      "[7930]\ttraining's binary_logloss: 0.163819\tvalid_1's binary_logloss: 0.244538\n",
      "[7940]\ttraining's binary_logloss: 0.163732\tvalid_1's binary_logloss: 0.244525\n",
      "[7950]\ttraining's binary_logloss: 0.163643\tvalid_1's binary_logloss: 0.244521\n",
      "[7960]\ttraining's binary_logloss: 0.163562\tvalid_1's binary_logloss: 0.244517\n",
      "[7970]\ttraining's binary_logloss: 0.163479\tvalid_1's binary_logloss: 0.244515\n",
      "[7980]\ttraining's binary_logloss: 0.1634\tvalid_1's binary_logloss: 0.244518\n",
      "[7990]\ttraining's binary_logloss: 0.163323\tvalid_1's binary_logloss: 0.244511\n",
      "[8000]\ttraining's binary_logloss: 0.16326\tvalid_1's binary_logloss: 0.244506\n",
      "[8010]\ttraining's binary_logloss: 0.163176\tvalid_1's binary_logloss: 0.244502\n",
      "[8020]\ttraining's binary_logloss: 0.16309\tvalid_1's binary_logloss: 0.244503\n",
      "[8030]\ttraining's binary_logloss: 0.163021\tvalid_1's binary_logloss: 0.244507\n",
      "[8040]\ttraining's binary_logloss: 0.162932\tvalid_1's binary_logloss: 0.244496\n",
      "[8050]\ttraining's binary_logloss: 0.162857\tvalid_1's binary_logloss: 0.244495\n",
      "[8060]\ttraining's binary_logloss: 0.162776\tvalid_1's binary_logloss: 0.244493\n",
      "[8070]\ttraining's binary_logloss: 0.162703\tvalid_1's binary_logloss: 0.244483\n",
      "[8080]\ttraining's binary_logloss: 0.162613\tvalid_1's binary_logloss: 0.244463\n",
      "[8090]\ttraining's binary_logloss: 0.162531\tvalid_1's binary_logloss: 0.244455\n",
      "[8100]\ttraining's binary_logloss: 0.162451\tvalid_1's binary_logloss: 0.244456\n",
      "[8110]\ttraining's binary_logloss: 0.162365\tvalid_1's binary_logloss: 0.244451\n",
      "[8120]\ttraining's binary_logloss: 0.162295\tvalid_1's binary_logloss: 0.244452\n",
      "[8130]\ttraining's binary_logloss: 0.162224\tvalid_1's binary_logloss: 0.244454\n",
      "[8140]\ttraining's binary_logloss: 0.162141\tvalid_1's binary_logloss: 0.244445\n",
      "[8150]\ttraining's binary_logloss: 0.162066\tvalid_1's binary_logloss: 0.244444\n",
      "[8160]\ttraining's binary_logloss: 0.161978\tvalid_1's binary_logloss: 0.24443\n",
      "[8170]\ttraining's binary_logloss: 0.161897\tvalid_1's binary_logloss: 0.244429\n",
      "[8180]\ttraining's binary_logloss: 0.161818\tvalid_1's binary_logloss: 0.244416\n",
      "[8190]\ttraining's binary_logloss: 0.161748\tvalid_1's binary_logloss: 0.244418\n",
      "[8200]\ttraining's binary_logloss: 0.161674\tvalid_1's binary_logloss: 0.244423\n",
      "[8210]\ttraining's binary_logloss: 0.161587\tvalid_1's binary_logloss: 0.244417\n",
      "[8220]\ttraining's binary_logloss: 0.161512\tvalid_1's binary_logloss: 0.244411\n",
      "[8230]\ttraining's binary_logloss: 0.161435\tvalid_1's binary_logloss: 0.244404\n",
      "[8240]\ttraining's binary_logloss: 0.161357\tvalid_1's binary_logloss: 0.244397\n",
      "[8250]\ttraining's binary_logloss: 0.161287\tvalid_1's binary_logloss: 0.244399\n",
      "[8260]\ttraining's binary_logloss: 0.161215\tvalid_1's binary_logloss: 0.244393\n",
      "[8270]\ttraining's binary_logloss: 0.161134\tvalid_1's binary_logloss: 0.244392\n",
      "[8280]\ttraining's binary_logloss: 0.161066\tvalid_1's binary_logloss: 0.244393\n",
      "[8290]\ttraining's binary_logloss: 0.160982\tvalid_1's binary_logloss: 0.244393\n",
      "[8300]\ttraining's binary_logloss: 0.160903\tvalid_1's binary_logloss: 0.244384\n",
      "[8310]\ttraining's binary_logloss: 0.160828\tvalid_1's binary_logloss: 0.24438\n",
      "[8320]\ttraining's binary_logloss: 0.160755\tvalid_1's binary_logloss: 0.244384\n",
      "[8330]\ttraining's binary_logloss: 0.160691\tvalid_1's binary_logloss: 0.244384\n",
      "[8340]\ttraining's binary_logloss: 0.160619\tvalid_1's binary_logloss: 0.244383\n",
      "[8350]\ttraining's binary_logloss: 0.160551\tvalid_1's binary_logloss: 0.244392\n",
      "[8360]\ttraining's binary_logloss: 0.160474\tvalid_1's binary_logloss: 0.244398\n",
      "[8370]\ttraining's binary_logloss: 0.1604\tvalid_1's binary_logloss: 0.244394\n",
      "[8380]\ttraining's binary_logloss: 0.160323\tvalid_1's binary_logloss: 0.24439\n",
      "[8390]\ttraining's binary_logloss: 0.160254\tvalid_1's binary_logloss: 0.244391\n",
      "[8400]\ttraining's binary_logloss: 0.160177\tvalid_1's binary_logloss: 0.244388\n",
      "[8410]\ttraining's binary_logloss: 0.160104\tvalid_1's binary_logloss: 0.244386\n",
      "Early stopping, best iteration is:\n",
      "[8311]\ttraining's binary_logloss: 0.160824\tvalid_1's binary_logloss: 0.24438\n",
      "gender************************************\n",
      "confusion_matrix is \n",
      " [[0.942 0.058]\n",
      " [0.175 0.825]] \n",
      " \n",
      "test acc is \n",
      " 0.9033055555555556 \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.94      0.93    120352\n",
      "           2       0.88      0.83      0.85     59648\n",
      "\n",
      "    accuracy                           0.90    180000\n",
      "   macro avg       0.90      0.88      0.89    180000\n",
      "weighted avg       0.90      0.90      0.90    180000\n",
      "\n",
      "accuracy is 90.330556 , sen is 0.941995,spe is 0.825241 \n",
      "1.2633111111111113\n"
     ]
    }
   ],
   "source": [
    "# stand = StandardScaler()\n",
    "# stand.fit(train_age_x)\n",
    "# train_age_x, test_age_x = stand.transform(train_age_x),stand.transform(test_age_x)\n",
    "# 训练模型\n",
    "acc_age = lgb_model_age(train_x, test_x,train_y['age'], test_y['age'])\n",
    "# 训练模型\n",
    "acc_gender = lgb_model_gender(train_x, test_x,train_y['gender'], test_y['gender'])\n",
    "\n",
    "print(acc_age+acc_gender)\n",
    "\n",
    "# acc_gender2 = lgb_model_gender2(train_x, test_x,train_y['gender'], test_y['gender'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
