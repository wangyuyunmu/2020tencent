{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import time\n",
    "np.random.seed(2020)\n",
    "\n",
    "\n",
    "def lgb_model_age(train_x, test_x,train_y, test_y):\n",
    "    model = lgb.LGBMClassifier (objective = 'multiclass',\n",
    "                                num_class = 10,\n",
    "                                n_estimators = 200\n",
    "                               )\n",
    "#     model.fit(train_x,train_y,early_stopping_rounds=100,eval_set=eval_set=[(train_x,train_y),(test_x,test_y)],verbose = 10)\n",
    "    \n",
    "    \n",
    "    #设定搜索的xgboost参数搜索范围，值搜索XGBoost的主要6个参数\n",
    "    param_dist = {\n",
    "            'learning_rate':np.linspace(0.01,0.5,20),\n",
    "            'subsample':np.linspace(0.1,0.9,10),\n",
    "            'colsample_bytree':np.linspace(0.1,0.9,10),\n",
    "            'num_leaves' : range(32,128,6),\n",
    "            'reg_alpha' : np.linspace(0,0.1,10),\n",
    "            'reg_lambda' : np.linspace(0,0.1,10)\n",
    "            }\n",
    "\n",
    "    #RandomizedSearchCV参数说明，clf1设置训练的学习器\n",
    "    #param_dist字典类型，放入参数搜索范围\n",
    "    #scoring = 'neg_log_loss'，精度评价方式设定为“neg_log_loss“\n",
    "    #n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长\n",
    "    #n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU\n",
    "    SearchCV = RandomizedSearchCV(model,param_dist,cv = 5,scoring = 'neg_log_loss',n_iter=10,n_jobs = -1,verbose = 10)\n",
    "    \n",
    "    #在训练集上训练\n",
    "    SearchCV.fit(train_x,train_y)\n",
    "    \n",
    "    # # 模型存储\n",
    "    joblib.dump(SearchCV, 'w2v_lgb_age_SearchCV.pkl')\n",
    "    # # 模型预测\n",
    "    y_t_pred = SearchCV.predict(test_x)\n",
    "\n",
    "    # print(model.get_score(importance_type='weight'))\n",
    "    cm = confusion_matrix(test_y, y_t_pred)\n",
    "    np.set_printoptions(precision=3)                                    # 显示精度\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # 将样本矩阵转化为比率\n",
    "\n",
    "\n",
    "    print('age************************************')\n",
    "    print('confusion_matrix is \\n {:} \\n '.format(cm_normalized))\n",
    "    print('test acc is \\n {:} \\n '.format(np.sum(test_y==y_t_pred)/len(test_y)))\n",
    "    print(classification_report(test_y,y_t_pred))\n",
    "    print('accuracy is %f , sen is %f,spe is %f ' % (accuracy_score(test_y, y_t_pred) * 100,\n",
    "                                                     cm_normalized[0][0],cm_normalized[1][1] ))\n",
    "\n",
    "    return accuracy_score(test_y, y_t_pred)\n",
    "\n",
    "def lgb_model_gender(train_x, test_x,train_y, test_y):\n",
    "    model = lgb.LGBMClassifier (objective = 'binary',\n",
    "                                n_estimators = 100\n",
    "                               )\n",
    "#     model.fit(train_x,train_y,early_stopping_rounds=100,eval_set=eval_set=[(train_x,train_y),(test_x,test_y)],verbose = 10)\n",
    "    \n",
    "    \n",
    "    #设定搜索的xgboost参数搜索范围，值搜索XGBoost的主要6个参数\n",
    "    param_dist = {\n",
    "            'learning_rate':np.linspace(0.01,0.5,20),\n",
    "            'subsample':np.linspace(0.1,0.9,10),\n",
    "            'colsample_bytree':np.linspace(0.1,0.9,10),\n",
    "            'num_leaves' : range(32,128,6),\n",
    "            'reg_alpha' : np.linspace(0,0.1,10),\n",
    "            'reg_lambda' : np.linspace(0,0.1,10)\n",
    "            }\n",
    "    #RandomizedSearchCV参数说明，clf1设置训练的学习器\n",
    "    #param_dist字典类型，放入参数搜索范围\n",
    "    #scoring = 'neg_log_loss'，精度评价方式设定为“neg_log_loss“\n",
    "    #n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长\n",
    "    #n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU\n",
    "    SearchCV = RandomizedSearchCV(model,param_dist,cv = 5,scoring = 'neg_log_loss',n_iter=10,n_jobs = -1,verbose = 10)\n",
    "    \n",
    "    #在训练集上训练\n",
    "    SearchCV.fit(train_x,train_y)\n",
    "    \n",
    "    # # 模型存储\n",
    "    joblib.dump(SearchCV, 'w2v_lgb_gender_SearchCV.pkl')\n",
    "    # # 模型预测\n",
    "    y_t_pred = SearchCV.predict(test_x)\n",
    "\n",
    "    # print(model.get_score(importance_type='weight'))\n",
    "    cm = confusion_matrix(test_y, y_t_pred)\n",
    "    np.set_printoptions(precision=3)                                    # 显示精度\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # 将样本矩阵转化为比率\n",
    "\n",
    "    print('gender************************************')\n",
    "    print('confusion_matrix is \\n {:} \\n '.format(cm_normalized))\n",
    "    print('test acc is \\n {:} \\n '.format(np.sum(test_y==y_t_pred)/len(test_y)))\n",
    "    print(classification_report(test_y,y_t_pred))\n",
    "    print('accuracy is %f , sen is %f,spe is %f ' % (accuracy_score(test_y, y_t_pred) * 100,\n",
    "                                                     cm_normalized[0][0],cm_normalized[1][1] ))\n",
    "    return accuracy_score(test_y, y_t_pred)\n",
    "\n",
    "def load_data():\n",
    "    # user\n",
    "    data = pd.read_csv('w2v_feat_data/train_data.csv')\n",
    "    data = data.head(200000)\n",
    "    label = data[['age','gender']]\n",
    "    \n",
    "    data = data.drop(['user_id','age','gender'],axis = 1)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label = load_data()\n",
    "#划分age的训练和测试数据\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.8,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   37.0s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   38.8s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   40.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender************************************\n",
      "confusion_matrix is \n",
      " [[0.952 0.048]\n",
      " [0.389 0.611]] \n",
      " \n",
      "test acc is \n",
      " 0.838625 \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.95      0.89      5345\n",
      "           2       0.86      0.61      0.72      2655\n",
      "\n",
      "    accuracy                           0.84      8000\n",
      "   macro avg       0.85      0.78      0.80      8000\n",
      "weighted avg       0.84      0.84      0.83      8000\n",
      "\n",
      "accuracy is 83.862500 , sen is 0.951543,spe is 0.611299 \n",
      "time spend  48.47770118713379\n"
     ]
    }
   ],
   "source": [
    "# star = time.time()\n",
    "# acc_age = lgb_model_age(train_x, test_x,train_y['age'], test_y['age'])\n",
    "# end = time.time()\n",
    "# print('time spend ',end-star)\n",
    "\n",
    "star = time.time()\n",
    "acc_gender = lgb_model_gender(train_x, test_x,train_y['gender'], test_y['gender'])\n",
    "end = time.time()\n",
    "print('time spend ',end-star)\n",
    "\n",
    "# print(acc_age+acc_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是采用贝叶斯方法优化一下，大概取10,0000样本就可以"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
